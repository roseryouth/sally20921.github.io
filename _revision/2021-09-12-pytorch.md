---
layout: post
title:  "Advanced PyTorch: Things You Didn't Know"
author: seri
categories: [ PyTorch ]
image: assets/images/pytorch.png
tags: featured
excerpt: "This blog post is for those who know the basics of PyTorch but want to go a step further. We will be diving into principles and applications of deep learning via PyTorch."
highlighter: rouge
---

<!--more-->

<h2> Flatten Operation for a Batch of Image Inputs to a CNN 
</h2>
Flattening specific tensor axis is often required with CNNs because we work with batches of inputs opposed to single inputs. A tensor flatten operation is a common operation inside convolutional neural networks. This is because convolutional layer outputs that are passed to fully connected layers must be flattened out so that the fully connected layer can accept them as the input. A flatten operation is a specific type of reshaping operation where by all of the axes are smooshed or squashed together. 

To flatten a tensor, we need to have at least two axes. This makes it so that we are starting with something that is not already flat. For example, in the MNIST dataset, we will look at an handwritten image of eight. This image has 2 distinct dimensions, height and width.

The height and width are $18 \times 18$ respectively. These dimensions tell use that this is a cropped image becaue the MNIST dataset contains $28 \times 28$ images. Let's see how these two axes of height and width are flattened out into a single axis of length 324 (c.f. 324 what we get when multiplying 18 with 18). 

<h3> Flattening Specific Axes of a Tensor </h3>

Tensor inputs to a convolutional neural network typically have 4 axes, one for batch size, one for color channels, and one each for height and width.

$$
[B,C,H,W]
$$

Suppose we have the following three tensors:

{% highlight python %}
t1 = torch.tensor([
    [1,1,1,1],
    [1,1,1,1],
    [1,1,1,1],
    [1,1,1,1]
])

t2 = torch.tensor([
    [2,2,2,2],
    [2,2,2,2],
    [2,2,2,2],
    [2,2,2,2]
])

t3 = torch.tensor([
    [3,3,3,3],
    [3,3,3,3],
    [3,3,3,3],
    [3,3,3,3]
])
{% endhighlight %}

Each of these has a shape of $4 \times 4$, so we have three rank-2 tensors. For our purpose, we'll consider these to be three $4 \times 4$ images that we will use to create a batch that can be passed to a CNN. Batches are represented using a single tensor, so we'll need to combine these three tensors into a single larger tensor that has 3 axes instead of 2. 

```python
t = torch.stack((t1, t2, t3))
t.shape 
> torch.Size([3,4,4])
```
Here, we used the `stack()` method to concatenate our sequence of tensors along a new axis. Since we have three tensors along a new axis, we know that the length of this axis should be 3. At this point, we have a rank-3 tensor that contains a batch of three $4 \times 4$ images. All we need to do now to get this tensor into a form that a CNN expects is add an axis for the color channels. We basically have an implicit single color channel for each of these image tensors, so in practice, these would be grayscale images. 

```python
torch.reshape(3,1,4,4)
```
Notice how the additional axis of length 1 doesn't change the number of elements in the tensor. This is because the product of the components values doesn't change when we multiply by one.

The first axis has 3 elements. Each element of the first axis represents an image. For each image, we have a single color channel on the channel axis. Each of these channels contain 4 arrays that contain 4 numbers or scalar components.

<h3> Flattening the Tensor Batch </h3>

Let's see how to flatten images in this batch. Remember the whole batch is a single tensor that will be passed to the CNN, <span class="underline"> we don't want to flatten the whole thing </span> We only want to <span class="glow"> flatten the image tensors </span> within the batch tensor. 

For example, if we do the following operations on `t`:
```python
t.flatten() 
>> tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])

# this is the same operation as t.flatten()
t.reshape(-1)
```
What I want you to notice about this output is that we have flattened the entire batch, and this smashes all the batches together into a single axis. The flattened batch won't work well inside our CNN because we need individual predictions for each image within our batch tensor, and now we have a flattened mess. 

The solution here, is to flatten each image while <span color="blink"> still maintaining the batch axis </span>. This means we want to <span class="underline"> flatten only part of the tensor </span>. We want to flatten the color channel axis with the height and width axes. 

<blockquote> The Axes that Need to be Flattened: $[C,H,W]$ </blockquote>
This can be done with PyTorch's built in `flatten()` function.
```python
t.flatten(start_dim=1).shape
>> torch.Size([3,16])

t.flatten(start_dim=1)
>> [
    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
    [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
    [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]
]
)
```
Notice how we specified the `start_dim` parameter.This tells the `flatten()` method which axis it should start the flatten operation. Now we have a rank-2 tensor with three single color channel images that have been flattened out into 16 pixels.

<h3> Flattening an RGB Image </h3>
If we flatten an RGB image, what happens to the color? Each color channel will be flattened first, then the flattened channels will be lined up side by side on a single axis of the tensor. 

For example, we build an RGB image tensor like the following code:
```python
r = torch.ones(1,2,2)
g = torch.ones(1,2,2)+1
b = torch.ones(1,2,2)+2

img = torch.cat((r,g,b),dim=0)
img.shape
>> torch.Size([3,2,2])
```
By flattening the image tensor, this is how it is going to look like.
```python
img.flatten(start_dim=0)
>> tensor([1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.])
```
<h2> Broadcasting and Element-Wise Operations with PyTorch </h2>

<blockquote> Remember, all these rules apply to PyTorch Tensors! Python built-in types such as list will not behave this way.</blockquote> 
<h3> Element-Wise Operations </h3>
An element-wise operation is an operation between two tensors that operates on corresponding elements within the respective tensors. Two elements are said to be corresponding if the two elements occupy the same position within the tensor. The position is determined by the indexes used to locate each element. Therefore, we can deduce that tensors must have the same shape in order to perform an element-wise operation. 

<h3> Broadcasting Tensors </h3>
Broadcasting describes how tensors with different shapes are treated during element-wise operations. For example, suppose we have the following two tensors:
```python
t1 = torch.tensor([[1,1],[1,1]],dtype=torch.float32)
t1.shape
>> torch.Size([2,2])

t2 = torch.tensor([2,4], dtype=torch.float32)
t2.shape
>> torch.Size([2])
```
What will be the result of this two tensors' element-wise addition operation? Even though these two tensors have differing shapes, the element-wise operation is possible, and broadcasting is what makes the operation possible. The lower rank tensor `t2` will be transformed via broadcasting to match the shape of the higher rank tensor `t1`, and the element-wise operation will be performed as usual.

The concept of broadcasting is the key to understanding how this operation will be carried out. We can check the broadcast transformation using the `broadcast_to()` numpy function. 
```python
np.broadcast_to(t2.numpy(), t1.shape)
>> array([[2., 4.],
        [2., 4.]], dtype=float32)

t1 + t2
>> tensor([[3., 5.],
        [3., 5.]])
```
When do we actually use broadcasting? We often need to use broadcasting when we are preprocessing and especially during normalization routines. 

<h3> Element-Wise Operation Applies to Comparision and Functions </h3>
Comparison operations are also element-wise operations. For a given comparison operation between two tensors, a new tensor of the same shape is returned with each element containing `torch.bool` value of `True` or `False`. It is also fine to assume that the function is applied to each element of the tensor. 

<div class="sidenote"> there are other ways to refer to element-wise operations, such as component-wise or point-wise </div>

<h2> Argmax and Reduction Operations for Tensors </h2>
Now, we will focus in on the frequently used `argmax()` function, and we'll see how to access the data inside our tensors.

<h3> Tensor Reduction Operation </h3>

<blockquote> A reduction operation on a tensor is an operation that reduces the number of elements contained within the tensor.</blockquote>

Reduction operations allow us to perform operations on element within a single tensor. Let's look at an example. Suppose we have the following rank-2 tensor:
```python
t = torch.tensor([[0,1,0],[2,0,2],[0,3,0]],dtype=torch.float32)
t.sum()
>> tensor(8.)

t.numel()
>> 9

t.sum().numel()
>> 1
```
The sum of our tensor's scalar components is calculated using the `sum()` tensor method. The result of this call is a <span class="rainbow"> scalar-valued tensor </span>. Since the number of elements have been reduced by the operation, we can conclude that the `sum()` method is a reduction operation. 

Other common reduction functions include `t.sum()`, `t.prod()`, `t.mean()` or `t.std()`. All of these tensor methods reduce the tensor to a single element scalar valued tensor by operating on all the tensor's elements.

Reduction operations in general allow us to compute aggregate values across data structures. But do reduction operations always reduce to a tensor with a single element? The answer is no. In fact, we often reduce specific axes at a time. This process is important.  

<h2> References </h2>
<ul><li><a href="https://deeplizard.com/learn/video/K3lX3Cltt4c"> deeplizard </a></li></ul>

