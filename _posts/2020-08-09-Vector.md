---
layout: post
title: Vector
categories: Linear-Algebra
tags: [Linear Algebra Coding with Python]
excerpt: Linear Algebra Coding with Python
---

# Preface 
* Arrays are the basis of data science because they ahve structures of vectors and matrices that  give the meaning  of direction and magnitude to each value in the dataset. The matrix structure allows transformation  to a simple form  without losing the basic characteristics  of a vast data set. These transformations are  useful for efficient processing of data and for  finding implicit characteristics.  
* Linear Algebra, a field that provides a basic theory of vectors and matrices, provides many algorithms to increase the  accuracy and speed of computation  for analyzing data and to discover the  characteristics of a dataset. These algorithms  are  very useful for understanding the computing  process of probability, statistics and the learning machine. 

# Dimension and axis
```python
#row vector
a = np.array([1,2])

#column vector
a1 = np.array([[1],[2]])
```
* for **a**, they appear on one axis, but for **a1**, on a plane formed by two axes, x and y.
Therefore, **a** can be represented in one dimension, but **a1** can only be displayed in two dimensions. 
* A vector is  any quantity that has a position and size, and a matrix means combining multiple vectors. In this sense, **a1** can be regarded as a matrix by combining  two row vectors. 
* In Python, a  single vector is represented in the form of (# of elements, ), and a collection of multiple vectors such as **a1** above, that is, a  matrix is expressed as (# of rows, # of columns)

* Brackets ([]): refers to the axis. The number of  square brackets within the object determines the dimension.

```python
arr = np.array([[5,3,-2,-3],[3,-4,-4,5]])
print(arr.ndim)
# 2
print(arr.shape)
# (2,4)
```
* In the case of object **arr**, there are  two brackets, which means two axes. The  presence of two axes represents a plane, or two-dimensional. In summary, one axis represents a line, or one-dimensional, and three axes represents a space. or three-dimensional. In this way, the concept of dimension represents direction as well as size. Then, the scalar that represents only the size is called 0-dimensional without dimension. 
* The object arr is a two-dimensional matrix of two rows and four columns. 
* There are cases where the shape or dimension of vectors and matrices needs to be changed in their operation. To convert the structure of an array object, we apply **np.reshape** function. The argument  of this function is the number of rows and columns to  switch. 
 * In the following code, the number of rows as an argument is -1. This means that  the value is automatically assigned based on the value of the other argument, the column. In the following cases, the number of rows is automatically adjusted based on the number of columns 2. 
 
# Norm and Unit Vector
* The distance is called norm or Euclidean distance. You can use the  np.linalg.norm(x) function for norm calculation. If the start point is not specified, it is considered as the origin. 
```python
import numpy.linalg as la
la.norm([[5,0], [3,0]])
```
* The unit vector is a vector whose size (norm) is 2. 
```python
a = np.array([[2],[7]])
a_norm = la.norm(a)
a_unit = a/a_norm
la.norm(a_unit)
# 1.0
```

# Vector Operations 
## Addition and subtraction, and scalar times
* Vector operations are performed between elements with the same index. Therefore, there is no operation between different  types of vectors. 
 * The addition operation of two vectors is the same as the vector corresponding to the diagonal of a parallelogram that both vectors can produce. 
 * Subtraction is the same as the addition operation with the result of multiplying b by scalar -1. The result of subtraction is the same as the vector representing the diagonal of the parallelogram between vector a and vector -b. 
 
## Inner product
* The dot product is the inner product of both vectors. Therefore, the number of front vector columns and the number of back vector rows must  be the same. This method for dot products applies equally between matrices and is called matrix multiplication.The matrix product is calculated using the **np.dot(x,y)** function. 
* If the two vectors a and b have the same structure, the shape must be converted by exchanging the rows and columns of the vector. This is said to **transpose** the vector.
* The  transpostion of an object  uses the **obj.T** property or **np.transpose(obj)** function.

```python
a = np.array([[2],[7]])
b = np.array([[5],[2]])
print(a.shape)
# (2,1)
print(b.shape)
# (2,1)
at = a.T #array([[2,7]])
print(at.shape)
#  (1,2)
innerp = np.dot(at, b)
print(innerP) #[[24]]
```
* Because the dot product is a scalar value that  characterizes the vector, the preceding vector must be converted  to  a row vector.
* The dot product can be calculated by applying  the angle between  two vectors. Conversely, the  angle between two vectors can be  calculated  using the lengths and  dot products of the vectors. 
* The  dot  product (inner product)  is the  product of the length  of vector (norm, Euclidean distance) a and the length of vector b projected over it. 
* The above  calculation is performed using numpy functions such as **np.cos()**.
* The degree must be  converted to  radians by applying **np.radians** before passing the argument to numpy's trigonometric functions. 
```python
# calculate  the angle between  vectors a and b
a = np.array([[-2],[1]])
b = np.array([[-3],[1]])
ab = np.dot(a.T, b)
a_norm = la.norm(a)
b_norm = la.norm(b)
cos = ab/(a_norm*b_norm)
rad = np.arccos(cos)
deg = np.rad2deg(rad)
print(deg) # [[8.13010235]]
```

# Orthogonal vectors 
* If the two vectors are at right angles, the dot product is zero. These  vectors are called **orthogonal vectors**. If two vectors have  a vertical relationship, they are said to represent **orthogonality** in linear  algebra. 
 * The 0 vector is  orthogonal to all  vectors 
 
# Cauchy-Schwarz inequality
* You can use the dot product of  the vector and the norm to  define the  relationship of the inequality. For any two vectors, the dot product is less  than or equal to the product of each vector's norm. 
* The equal sign is established when  the two vectors are multiples of each other.
```python
u = np.array([[-1], [2]])
v = np.array([[4], [-2]])
inner = np.dot(u.T, v)
print(abs(inner)) #[[8]]
normProd =  la.norm(u) * la.norm(v)
print(round(normProd, 3)) # 10.000
```

# Triangle inequality 
* THe  norm of two vectors sums is less than or equal to  the sum of each vector norm.

# Projections
* When light is irradiated perpendicularly to the vector b, the position vector of the shadow of b generated in the vector a is called projection. 
* b_proj is the projection of b located above the vector a, so the size  of the  projection can be expressed as a multiple of the unit vector of a. Therefore, the projection can be calculated by the dot  product of two vectors and the norm. 

# Outer Product
* Vectors that are  perpendicular to  any two vectors are produced by cross product. The cross product of two 3-dimensional vectors can be calculated using the **np.cross()** function. 
