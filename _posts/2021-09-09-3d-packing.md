---
layout: post
title: "3D Packing for Self-Supervised Depth Estimation"
author: seri
categories: [ paper ]
image: assets/images/cnn.png
tags: featured
excerpt: "This paper proposes a self-supervised monocular depth estimation method leveraging 3D convolutions. It does not require pretraining on ImageNet and can run it in real-time."
---

<!--more-->

<h2> Self-Supervised Scale-Aware SfM </h2>

Self-supervised monocular SfM training aims to learn the following:
<ul><li> a monocular <u>depth model</u> $f_D: I \rightarrow D$ that predicts the scale ambiguous depth $\hat{D} = f_D(I(p))$ for every pixel $p$ in the target image $I$. </li>
<li> a monocular <u>egomotion estimator</u> $ f_x: (I_t, I_S) \rightarrow x_{t \rightarrow s}$ that predicts the set of 6-DoF rigid transformations for all $s \in S$ given by $x_{t \rightarrow s} = \begin{bmatrix} R & t \\ 0 & 1 \end{bmatrix} \in SE(3)$, between the target image $I_t$ and the set of source images $I_s \in I_S$ considered as part of the temporal context. </li>

<h3> Self-Supervised Objective </h3>
<blockquote> The overall objective loss is: 

$$
L(I_t, \hat{I_t}, v) = L(I_t, \hat{I_t}) + \lambda_2 L_v(t \rightarrow s, v)
$$

where 

$$ 
L(I_t, \hat{I_t}) = L_p(I_t, I_S) \odot 


</blockquote>

<div class="sidenote"> why recover the inverse depth `$f_d: I \rightarrow f^{-1}_{D}(I)$`? features that are very far off would have a distance estimate of infinity. To get around it, the inverse of the distance is estimated, and all the infinity becomes zero </div>

The monocular <b> depth </b> $f_d$ and <b> ego-motion </b> estimators $f_x$ predict <span class="glow"> scale-ambiguous </span> values. All previous approaches resort to artificially incorporating this scale factor at testt time, using LiDAR measurements. 

<h3> Velocity Supervision Loss </h3>

The authors directly incorporate <span class="rainbow"> instantaneous velocity measurements </span> in the self-supervised objective to learn a metrically accurate monocular depth estimator. 

Additional velocity loss allows the <u> pose network </u> to make metrically accurate predictions. Subsequently <u> the depth network </u> also learns metrically accurate estimates to maintain consistency. 

