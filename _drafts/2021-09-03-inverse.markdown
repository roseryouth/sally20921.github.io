---
layout: post
title:  "Inverse Projection Transformation"
author: seri
categories: [ computer vision ]
image: assets/images/depth/12.png
tags: featured
excerpt: "When an image of a scene is captured by a camera, we lose depth information. This is also known as projective transformation, in which points in the world are converted to pixels on a 2D plane. But how do we do the opposite?"
---

<!--more-->

<div align="center"><h2> Depth and Inverse Projection </h2></div>

<picture><img src="/assets/images/depth/11.png"></picture> 

<div class="caption"> RGB + Depth = 3D Back-Projected Points </div>

<p> When an image of a scene is captured by a camera, we <span class="circle-sketch-highlight"> lose depth information as objects and points in 3D space are mapped onto a 2D image plane. This is also known as <span class="blue"> projective transformation </span>, in which points in the world are converted to <span class="highlight-green">pixels</span> on a 2D plane. </p>

<p>However, what if we want to do the <span class="underline"> inverse </span>? That is, we want to recover and reconstruct the scene given only 2D image. To do that, we would need to know the depth or $Z$-component of each corresponding pixels. Depth can be represented as an image as shown in the figure above, with brigther intensity denoting points further away. </p>

In this blog post, we will take a tour and understand the mathematics and concepts of performing back-projection from 2D pixel coordinates to 3D points. We will assume that a depth map is provided to perform the 3D reconstruction. The concept that we will go through are camera calibration parameters, projective transformation using intrinsic and its inverse, and coordinate transformation between frames.  

<div align="center"><h2> Central Projection of Pinhole Camera Model </h2></div>

First and foremost, understanding the geometrical model of the camera projection serves as the core idea. What we are ultimately interested in is the depth, parameter $Z$. Here, we consider the simplest pinhole camera model with no skew or distortion factor. 

3D points are mapped to the image plane $(u,v) = f(X,Y,Z)$. The complete mathematical model that describes this transformation can be written as $p = K[R|t]*P$.

$$
s \begin{bmatrix} u \\ v \\ 1 \end{bmatrix} = \begin{bmatrix} f_x & 0 & u_0 \\ 0 & f_y & v_0 \\ 0 & 0 & 1 \end{bmatrix} \begin{bmatrix} r_{11} & r_{12} & r_{13} & t{1} \\ r_{21} & r_{22} & r_{23} & t_2 \\ r_{31} & r_{32} & r_{33} & t_3\end{bmatrix} \begin{bmatrix} X \\ Y \\ Z \\ 1 \end{bmatrix}
$$

, where <ul><li> $p$ is the projected point on the image plane</li>
<li> $K$ is the camera intrinsics matrix</li>
<li> $[R|t]$ is the extrinsic parameters describing the relative transformation of the point in the world frame to the camera frame </li>
<li> $P$ or $[X, Y, Z, 1]$ represents the 3D point expressed in a predefined world coordinate system in Euclidean space </li>
<li> Aspect ratio scaling $s$ controls how pixels are scaled in the $x$ and $y$ direction as focal length chnanges</li> </ul>

<h3> Intrinsic Parameter Matrix </h3>

<picture><img src="/assets/images/depth/13.png"></picture> 
<div class="caption"> Camera Projective Geometry </div>

The matrix $K$ is responsible for projecting 3D points to the image plane. To do that, the following quantities must be defined as:

* Focal length $(f_x, f_y)$: measure the position of the image plane with respect to the camera center.
* Principal point $(u_0, v_0)$; the optical center of the image plane
* Skew factor: the misalignment from a square pixel if the image plane axes are not perpendicular. In our example, this is set to zero.

The most common way of solving all the paramters is using the <span class="reveal"> checkerboard method</span>, where several 2D-3D correspondences obtained through matching and solving the unknown parameters by means of PnP, Direct Linear Transform or RANSAC to improve robustness. 

With all the unknowns determined, we can finally proceed to recover the 3D points $(X,Y,Z)$ by applying the inverse. 

<h3> Back-Projection </h3>

Suppose $(X,Y,Z,1)$ is in the camera coordinate frame, i.e. we do not need to consider the extrinsic matrix $[R|t]$.

## References
- <a href="https://towardsdatascience.com/inverse-projection-transformation-c866ccedef1c"> MEDIUM </a>

