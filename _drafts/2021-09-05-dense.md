---
layout: post
title:  "Dense Depth Using Stereo Vision"
author: seri
categories: [ computer vision ]
image: assets/images/depth/12.png
tags: featured
excerpt: What exactly is this all-important dense depth that stereo vision makes possible? When we talk about dense depth, we mean we can take the video we capture from our car's cameras and tell you exactly how far away everything (every pixel) is. 
---

<div align="center"><h2> Stereo Vision Unlocks Dense Depth </h2></div>

<picture> <img src="{{site.baseurl}}/assets/images/dense.jpeg"> </picture>
<div class="caption"> Sparse Depth Provided by LiDAR (left) and Dense Depth which Stereo Vision Gives Us (right) </div>

What exactly is this all-important dense depth that stereo vision makes possible? When we talk about dense depth, we mean we can take the video we capture from our car's cameras and tell you exactly how far away everything (by everything, every pixel) is. This contrasts with the <span class="highlight-sketch"> sparse depth </span> you get from LiDAR, where highly accurate depth calculations are achieved but only for a small fraction of the visible points in a video. 

<div align="center"><h2> Dense Depth Matters, Because Safety Matters </h2></div>

Dense depth is a must. Why? First up, seeing in 3D is essential for accurately classifying what we see in a scene. Secondly, <span class="blue"> seeing <span> with stereo vision's dense depth allows us to better classify the entirety of a complex scene and its unpredictable road layouts. 

In complex city environments, the sparse quality of other methods can lead to missing or indeterminate details. There can be areas in the scene whre it's hard, or impossible to determine the depth due to something blocking or partially blocking the sensors' view of that area. For example, one car may be partially obscured behind another. These partial <span class="blue"> occlussions <span> make it harder to understand the scene semantically. Dense depth gives us answers.

Third, dense depth also helps us combat wet, grey European weather. Rain and snow produce noise effects that obscure the scene. Dense depth allows to better overcome this inference. 

<div align="center"><h2> How Does It Work? </h2></div>

The cameras on our car are set up in pairs, left and right, with both cameras in the pair pointing in the same direction. The difference in position of the cameras gives them slightly different views of the world. We use this difference to estimate the distance to objects in the scene. 


Let's see how this works. For example, find a scene around you that's going to stay fairly stationary for the next couple of minutes-one with some close objects, and others further away. Look at one object that's further away, and as you do so, cover one eye then the other. Try to notice how the closer objects move from left to right as you switch eyes.

We calculate how far away an object is by measuring those changes in the horizontal position of close objects in relation to far objects. The larger the change in horizontal position, the close the object must be. If an object hardly moves at all, it must be very far away.

We calibrate our cameras so that, if an object is <span class="typewriter"> infinitely far away </span> it will appear in teh same pixel in both left and right cameras. By matching the pixels in the image from left hand camera corresponding to the same object in the right hand camera, we can measure the difference in the position of those two pixels in teh two frames. We can then take this disparity and calculate the distance to the object.



## References
- <a href="https://medium.com/fiveai/dense-depth-using-stereo-vision-to-see-european-city-streets-fd4fa65885c9"> article from medium </a>

