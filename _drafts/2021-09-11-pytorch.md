---
layout: post
title:  "Deep Learning with PyTorch"
author: seri
categories: [ PyTorch ]
image: assets/images/depth/1.jpg
tags: featured
---

<h2> Flatten Operation for a Batch of Image Inputs to a CNN 
</h2>
Flattening specific tensor axis is often required with CNNs because we work with batches of inputs opposed to single inputs. A tensor flatten operation is a common operation inside convolutional neural networks. This is because convolutional layer outputs that are passed to fully connected layers must be flattened out so that the fully connected layer can accept them as the input. A flatten operation is a specific type of reshaping operation where by all of the axes are smooshed or squashed together. 

To flatten a tensor, we need to have at least two axes. This makes it so that we are starting with something that is not already flat. For example, in the MNIST dataset, we will look at an handwritten image of eight. This image has 2 distinct dimensions, height and width.

The height and width are $18 \times 18$ respectively. These dimensions tell use that this is a cropped image becaue the MNIST dataset contains $28 \times 28$ images. Let's see how these two axes of height and width are flattened out into a single axis of length 324 (c.f. 324 what we get when multiplying 18 with 18). 

<h3> Flattening Specific Axes of a Tensor </h3>

Tensor inputs to a convolutional neural network typically have 4 axes, one for batch size, one for color channels, and one each for height and width.
$$
[B,C,H,W]
$$

Suppose we have the following three tensors:
```python
t1 = torch.tensor([
    [1,1,1,1],
    [1,1,1,1],
    [1,1,1,1],
    [1,1,1,1]
])

t2 = torch.tensor([
    [2,2,2,2],
    [2,2,2,2],
    [2,2,2,2],
    [2,2,2,2]
])

t3 = torch.tensor([
    [3,3,3,3],
    [3,3,3,3],
    [3,3,3,3],
    [3,3,3,3]
])
```
Each of these has a shape of $4 \times 4$, so we have three rank-2 tensors. For our purpose, we'll consider these to be three $4 \times 4$ images that we will use to create a batch that can be passed to a CNN. Batches are represented using a single tensor, so we'll need to combine these three tensors into a single larger tensor that has 3 axes instead of 2. 

```python
t = torch.stack((t1, t2, t3))
t.shape 
> torch.Size([3,4,4])
```
Here, we used the `stack()` method to concatenate our sequence of tensors along a new axis. Since we have three tensors along a new axis, we know that the length of this axis should be 3. At this point, we have a rank-3 tensor that contains a batch of three $4 \times 4$ images. All we need to do now to get this tensor into a form that a CNN expects is add an axis for the color channels. We basically have an implicit single color channel for each of these image tensors, so in practice, these would be grayscale images. 

```python
torch.reshape(3,1,4,4)
```
Notice how the additional axis of length 1 doesn't change the number of elements in the tensor. This is because the product of the components values doesn't change when we multiply by one.

The first axis has 3 elements. Each element of the first axis represents an image. For each image, we have a single color channel on the channel axis. Each of these channels contain 4 arrays that contain 4 numbers or scalar components.

<h3> Flattening the Tensor Batch </h3>

Let's see how to flatten images in this batch. Remember the whole batch is a single tensor that will be passed to the CNN, <span class="underline"> we don't want to flatten the whole thing </span> We only want to <span class="glow"> flatten the image tensors </span> within the batch tensor. 

For example, if we do the following operations on `t`:
```python
t.flatten() 
>> tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,
    2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])

# this is the same operation as t.flatten()
t.reshape(-1)
```
What I want you to notice about this output is that we have flattened the entire batch, and this smashes all the batches together into a single axis. The flattened batch won't work well inside our CNN because we need individual predictions for each image within our batch tensor, and now we have a flattened mess. 

The solution here, is to flatten each image while <span color="blink"> still maintaining the batch axis </span>. This means we want to <span class="underline"> flatten only part of the tensor </span>. We want to flatten the color channel axis with the height and width axes. 

<blockquote> The Axes that Need to be Flattened: $[C,H,W]$ </blockquote>
This can be done with PyTorch's built in `flatten()` function.
```python
t.flatten(start_dim=1).shape
>> torch.Size([3,16])

t.flatten(start_dim=1)
>> [
    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
    [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
    [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]
]
)
```
Notice how we specified the `start_dim` parameter.This tells the `flatten()` method which axis it should start the flatten operation. Now we have a rank-2 tensor with three single color channel images that have been flattened out into 16 pixels.

<h3> Flattening an RGB Image </h3>





<picture><img src="{{site.baseurl}}/assets/images/disparity.png"></picture>

<h2> References </h2>
<ul><li><a=href=""> TheAILearner </a></li>
</ul>

