---
layout: post
title:  "Image Processing: the Basics"
author: seri
categories: [ computer vision ]
image: assets/images/depth/1.jpg
tags: featured
---

<h2> Introduction: What is a Digital Image? </h2>
A digital image is a numeric representation of a two-dimensional image and is made of picture elements called pixels, arranged in rows and columns. These numeric values are the intensity or brightness values that are associated with the pixels. 

The concept of pixel is closely related with image sensors. Image sensor is a device that converts the light energy into an electric signal. In digital cameras, these sensors are arranged in the form of a 2D array on a chip. Mostly there is a one-to-one correspondence between a pixel and a sensor meaning each sensor produces 1 pixel. Thus, the total number of pixels in an image is equal to the total number of sensors on a chip. Sometimes, multiple sensors are used to produce a pixel of information.

8MP camera means there are $8 \times 10^6$ image sensors in the camera chip and if there is a one-to-one correspondence between a pixel and a sensor then the image contains $8 \times 10^6$ pixels. Larger the pixel, better will be the image quality.

<h2> Grayscale and Color Image </h2>

A grayscaled image is the one where pixels contains only the intensity information and not wavelength. For example, a pixel value of 165 represents the amount of light captured by the sensor (which is basically the pixel). For an 8-bit image, there will be $2^8 = 256$ intensity levels where $0$ means no light(black) and $255$ means white light and in between levels are the representative of the shades of gray.

A color image, on the other hand, contains intensity information corresponding to three wavelengths red, green and blue collectively called primary colors or channels. The reason for choosing these 3 colors lies in the fact that cone cells in the human eye, that is responsible for color vision, are senstive to red, green and blue light. Now combining the primary colors in various intensity proportions produces all visible colors.

The drastic advancement in color image formation came with the introduction of digital sensors like CCD or CMOS. In 1976, Bryce Bayer invented the <span color="blue"> Bayer Filter </span> that revolutionized color image formation. Bayer Filter is a color filter array (CFA) in which RGB color filters are arranged in a pattern on the sensor. 

In the Bayer Filter, there are twice as many green elements compared to red and blue elements to mimic the human eye's greater resolving power with the green light. In order to construct an RGB picture, we calculate green and blue values for each red pixel, blue and red values for each green pixel and so on. This happens via interpolation or color demosaicing algorith.

<h2> Understanding Image Histograms </h2>

An image histogram tells us how the intensity values are distributed in an image. For 1D histogram, we plot the intensity values on the $x$-axis and the number of pixels corresponding to intensity values on the $y$-axis. We are taking only one feature into our consideration, i.e. grayscale intensity values of the pixel. 

For a dark image, the histogram will cover mostly the leftside and center of the graph, while for a bright image, the histogram mostly rests on the right side and center of the graph. Let's see how to plot histogram for an image using OpenCV.

```python
cv2.calcHist(image, channel, mask, bins, range):
	'''
	Parameters
	_____
	image: list
		input image
	channel: list
		index of the channel ([0],[1],[2])
	mask: provide if you want to calculate histogram for specific region otherwise pass None
	bins: int
		number of bins to use for each channel, should pass 255
	range: [0,256]
		range of intensity values for 8-bit pass as [0,256]

	Returns
	______
	numpy.ndarray [n_bins, 1]

	cf. why 1? % of pixels 
	'''
```
We then can plot the output using matplotlib.
```python 
import cv2
import matplotlib.pyplot as plt
image = cv2.imread('input.jpg',0)
hist = cv2.calcHist([image], [0], None, [256], [0,256])
plt.plot(hist)
```
<h2> Image Demosaicing or Interpolation Methods </h2>
According to Wikipedia, <span class="blue"> interpolation </span> is a method of constructing new data points within the range of a discrete set of known data points. Image interpolation refers to the "guess" of intensity values at missing locations.

The big question is why we need interpolation if we are able to capture intensity values at all pixels using image sensor? Well, there could be a scenario where we have to project low-resolution image to a high-resolution screen. For example, we prefer watching videos in the full-screen mode. Also, there coul be image inpainting, image warping or geometric transformations and so on. 

Interpolation algorithms can be classified as 

<div color="mermaid">
stateDiagram-v2
    Interpolation --> Adaptive
    Interpolation --> NonAdaptive
    NonAdaptive --> NearestNeighbor
    NonAdaptive --> Billinear
    NonAdaptive --> BiCubic
    Adaptive --> EdgeSensing
    Adaptive --> ColorCorrection
</div>

Non-adaptive perform interpolation in a fixed pattern for every pixel, while adaptive algorithms detect local spatial features, like edges, pixel neighborhood and make effective choices depending on the algorithm.

<h3> Nearest Neighbor Interpolation </h3>
The basic idea is simple:
<blockquote> We assign unknown pixels to the nearest known pixel. </blockquote>

The figure below shows an example of the Nearest Neighbor Interpolation. 
<picture><img src="{{site.baseurl}}/assets/images/NN.png"></picture>

The process can be summarized as folows:
1. Project $4 \times 4$ image on the $2 \times 2$ image. We can easily find out the coordinates of each unknown pixel.
2. Compare the above calculated coordinates of each unknown pixel with the input image pixels to find out the nearest pixel. 

This is the fastest interpolation method as it involves little calculation. This results in a blocky image. 

<h3> Bilinear Interpolation </h3>

Bilinear interpolation means applying a linear interpolation in two directions. Thus, it uses 4 nearest neighbors, takes their weighted average to produce the output.


<h2> References </h2>
<ul><li><a=href="https://theailearner.com/2018/10/06/what-is-a-digital-image/"> TheAILearner </a></li>
</ul>

