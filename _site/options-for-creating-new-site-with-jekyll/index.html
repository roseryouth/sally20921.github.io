<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Options for creating a new site with Jekyll | Seri Lee Blog</title>

    <!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Options for creating a new site with Jekyll | Seri Lee Blog</title>
<meta name="generator" content="Jekyll v3.9.0">
<meta property="og:title" content="Options for creating a new site with Jekyll">
<meta name="author" content="jane">
<meta property="og:locale" content="en_US">
<meta name="description" content="jekyll new &lt;PATH&gt; installs a new Jekyll site at the path specified (relative to current directory). In this case, Jekyll will be installed in a directory called myblog. Here are some additional details: To install the Jekyll site into the directory you’re currently in, run jekyll new . If the existing directory isn’t empty, you can pass the –force option with jekyll new . –force. jekyll new automatically initiates bundle install to install the dependencies required. (If you don’t want Bundler to install the gems, use jekyll new myblog --skip-bundle.) By default, the Jekyll site installed by jekyll new uses a gem-based theme called Minima. With gem-based themes, some of the directories and files are stored in the theme-gem, hidden from your immediate view. We recommend setting up Jekyll with a gem-based theme but if you want to start with a blank slate, use jekyll new myblog --blank To learn about other parameters you can include with jekyll new, type jekyll new --help.">
<meta property="og:description" content="jekyll new &lt;PATH&gt; installs a new Jekyll site at the path specified (relative to current directory). In this case, Jekyll will be installed in a directory called myblog. Here are some additional details: To install the Jekyll site into the directory you’re currently in, run jekyll new . If the existing directory isn’t empty, you can pass the –force option with jekyll new . –force. jekyll new automatically initiates bundle install to install the dependencies required. (If you don’t want Bundler to install the gems, use jekyll new myblog --skip-bundle.) By default, the Jekyll site installed by jekyll new uses a gem-based theme called Minima. With gem-based themes, some of the directories and files are stored in the theme-gem, hidden from your immediate view. We recommend setting up Jekyll with a gem-based theme but if you want to start with a blank slate, use jekyll new myblog --blank To learn about other parameters you can include with jekyll new, type jekyll new --help.">
<meta property="og:site_name" content="Seri Lee Blog">
<meta property="og:image" content="/assets/images/13.jpg">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2019-01-23T00:00:00+09:00">
<meta name="twitter:card" content="summary_large_image">
<meta property="twitter:image" content="/assets/images/13.jpg">
<meta property="twitter:title" content="Options for creating a new site with Jekyll">
<script type="application/ld+json">
{"author":{"@type":"Person","name":"jane"},"mainEntityOfPage":{"@type":"WebPage","@id":"/options-for-creating-new-site-with-jekyll/"},"url":"/options-for-creating-new-site-with-jekyll/","image":"/assets/images/13.jpg","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"/assets/images/logo.png"},"name":"jane"},"headline":"Options for creating a new site with Jekyll","dateModified":"2019-01-23T00:00:00+09:00","datePublished":"2019-01-23T00:00:00+09:00","description":"jekyll new &lt;PATH&gt; installs a new Jekyll site at the path specified (relative to current directory). In this case, Jekyll will be installed in a directory called myblog. Here are some additional details: To install the Jekyll site into the directory you’re currently in, run jekyll new . If the existing directory isn’t empty, you can pass the –force option with jekyll new . –force. jekyll new automatically initiates bundle install to install the dependencies required. (If you don’t want Bundler to install the gems, use jekyll new myblog --skip-bundle.) By default, the Jekyll site installed by jekyll new uses a gem-based theme called Minima. With gem-based themes, some of the directories and files are stored in the theme-gem, hidden from your immediate view. We recommend setting up Jekyll with a gem-based theme but if you want to start with a blank slate, use jekyll new myblog --blank To learn about other parameters you can include with jekyll new, type jekyll new --help.","@type":"BlogPosting","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

	
    <link rel="shortcut icon" type="image/x-icon" href="/assets/images/favicon.ico">

    <!-- Font Awesome Icons -->
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">

    <!-- Google Fonts-->
    <link href="https://fonts.googleapis.com/css?family=Lora:400,400i,700" rel="stylesheet">

    <!-- Bootstrap Modified -->
    <link rel="stylesheet" href="/assets/css/main.css">

    <!-- Theme Stylesheet -->
    <link rel="stylesheet" href="/assets/css/theme.css">

    <!-- Jquery on header to make sure everything works, the rest  of the scripts in footer for fast loading -->
    <script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>

    <!-- This goes before </head> closing tag, Google Analytics can be placed here --> 

     


</head>

<body class="">

    <!-- Navbar -->
    <nav id="MagicMenu" class="topnav navbar navbar-expand-lg navbar-light bg-white fixed-top">
    <div class="container">
        <a class="navbar-brand" href="/index.html"><strong>Seri Lee Blog</strong></a>
        <button class="navbar-toggler collapsed" type="button" data-toggle="collapse" data-target="#navbarColor02" aria-controls="navbarColor02" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
        </button>
        <div class="navbar-collapse collapse" id="navbarColor02" style="">
            <ul class="navbar-nav mr-auto d-flex align-items-center">
               <!--  Replace menu links here -->

<li class="nav-item">
<a class="nav-link" href="/index.html">Home</a>
</li>
<li class="nav-item">
<a class="nav-link" href="/authors-list.html">Authors</a>
</li>
<li class="nav-item">
<a class="nav-link" href="/contact.html">Contact</a>
</li>
<li class="nav-item">
<a target="_blank" class="nav-link" href="https://www.wowthemes.net/themes/mundana-wordpress/">WP</a>
</li>
<li class="nav-item">
<a target="_blank" class="nav-link" href="https://www.wowthemes.net/themes/mundana-ghost/">Ghost</a>
</li>
<li class="nav-item">
<a target="_blank" class="nav-link" href="https://www.wowthemes.net/donate/">Buy me a coffee <i class="fa fa-coffee text-danger"></i></a>
</li>

            </ul>
            <ul class="navbar-nav ml-auto d-flex align-items-center">
                <script src="/assets/js/lunr.js"></script>

<script>
$(function() {
    $("#lunrsearchresults").on('click', '#btnx', function () {
        $('#lunrsearchresults').hide( 1000 );
        $( "body" ).removeClass( "modal-open" );
    });
});
    

var documents = [{
    "id": 0,
    "url": "/404/",
    "title": "",
    "body": " 404 Page not found :(  The requested page could not be found. "
    }, {
    "id": 1,
    "url": "/",
    "title": "Mundana Free Jekyll Theme",
    "body": "  {% if page. url ==  /  %}            {% assign latest_post = site. posts[0] %}          &lt;div class= topfirstimage  style= background-image: url({% if latest_post. image contains  ://  %}{{ latest_post. image }}{% else %} {{site. baseurl}}/{{ latest_post. image}}{% endif %}); height: 200px;  background-size: cover;  background-repeat: no-repeat; &gt;&lt;/div&gt;           {{ latest_post. title }}  :       {{ latest_post. excerpt | strip_html | strip_newlines | truncate: 136 }}               In         {% for category in latest_post. categories %}        {{ category }},         {% endfor %}                                {{ latest_post. date | date: '%b %d, %Y' }}                            {%- assign second_post = site. posts[1] -%}                        {% if second_post. image %}                         &lt;img class= w-100  src= {% if second_post. image contains  ://  %}{{ second_post. image }}{% else %}{{ second_post. image | absolute_url }}{% endif %}  alt= {{ second_post. title }} &gt;                        {% endif %}                                    {{ second_post. title }}          :                       In             {% for category in second_post. categories %}            {{ category }},             {% endfor %}                                                      {{ second_post. date | date: '%b %d, %Y' }}                                    {%- assign third_post = site. posts[2] -%}                        {% if third_post. image %}                         &lt;img class= w-100  src= {% if third_post. image contains  ://  %}{{ third_post. image }}{% else %}{{site. baseurl}}/{{ third_post. image }}{% endif %}  alt= {{ third_post. title }} &gt;                        {% endif %}                                    {{ third_post. title }}          :                       In             {% for category in third_post. categories %}            {{ category }},             {% endfor %}                                                      {{ third_post. date | date: '%b %d, %Y' }}                                    {%- assign fourth_post = site. posts[3] -%}                        {% if fourth_post. image %}                        &lt;img class= w-100  src= {% if fourth_post. image contains  ://  %}{{ fourth_post. image }}{% else %}{{site. baseurl}}/{{ fourth_post. image }}{% endif %}  alt= {{ fourth_post. title }} &gt;                        {% endif %}                                    {{ fourth_post. title }}          :                       In             {% for category in fourth_post. categories %}            {{ category }},             {% endfor %}                                                      {{ fourth_post. date | date: '%b %d, %Y' }}                                  {% for post in site. posts %} {% if post. tags contains  sticky  %}                    {{post. title}}                  {{ post. excerpt | strip_html | strip_newlines | truncate: 136 }}                 Read More            	             {% endif %}{% endfor %}  {% endif %}                All Stories:         {% for post in paginator. posts %}          {% include main-loop-card. html %}        {% endfor %}                   {% if paginator. total_pages &gt; 1 %}              {% if paginator. previous_page %}        &laquo; Prev       {% else %}        &laquo;       {% endif %}       {% for page in (1. . paginator. total_pages) %}        {% if page == paginator. page %}        {{ page }}        {% elsif page == 1 %}        {{ page }}        {% else %}        {{ page }}        {% endif %}       {% endfor %}       {% if paginator. next_page %}        Next &raquo;       {% else %}        &raquo;       {% endif %}            {% endif %}                     {% include sidebar-featured. html %}      "
    }, {
    "id": 2,
    "url": "/page2/",
    "title": "Mundana Free Jekyll Theme",
    "body": "  {% if page. url ==  /  %}            {% assign latest_post = site. posts[0] %}          &lt;div class= topfirstimage  style= background-image: url({% if latest_post. image contains  ://  %}{{ latest_post. image }}{% else %} {{site. baseurl}}/{{ latest_post. image}}{% endif %}); height: 200px;  background-size: cover;  background-repeat: no-repeat; &gt;&lt;/div&gt;           {{ latest_post. title }}  :       {{ latest_post. excerpt | strip_html | strip_newlines | truncate: 136 }}               In         {% for category in latest_post. categories %}        {{ category }},         {% endfor %}                                {{ latest_post. date | date: '%b %d, %Y' }}                            {%- assign second_post = site. posts[1] -%}                        {% if second_post. image %}                         &lt;img class= w-100  src= {% if second_post. image contains  ://  %}{{ second_post. image }}{% else %}{{ second_post. image | absolute_url }}{% endif %}  alt= {{ second_post. title }} &gt;                        {% endif %}                                    {{ second_post. title }}          :                       In             {% for category in second_post. categories %}            {{ category }},             {% endfor %}                                                      {{ second_post. date | date: '%b %d, %Y' }}                                    {%- assign third_post = site. posts[2] -%}                        {% if third_post. image %}                         &lt;img class= w-100  src= {% if third_post. image contains  ://  %}{{ third_post. image }}{% else %}{{site. baseurl}}/{{ third_post. image }}{% endif %}  alt= {{ third_post. title }} &gt;                        {% endif %}                                    {{ third_post. title }}          :                       In             {% for category in third_post. categories %}            {{ category }},             {% endfor %}                                                      {{ third_post. date | date: '%b %d, %Y' }}                                    {%- assign fourth_post = site. posts[3] -%}                        {% if fourth_post. image %}                        &lt;img class= w-100  src= {% if fourth_post. image contains  ://  %}{{ fourth_post. image }}{% else %}{{site. baseurl}}/{{ fourth_post. image }}{% endif %}  alt= {{ fourth_post. title }} &gt;                        {% endif %}                                    {{ fourth_post. title }}          :                       In             {% for category in fourth_post. categories %}            {{ category }},             {% endfor %}                                                      {{ fourth_post. date | date: '%b %d, %Y' }}                                  {% for post in site. posts %} {% if post. tags contains  sticky  %}                    {{post. title}}                  {{ post. excerpt | strip_html | strip_newlines | truncate: 136 }}                 Read More            	             {% endif %}{% endfor %}  {% endif %}                All Stories:         {% for post in paginator. posts %}          {% include main-loop-card. html %}        {% endfor %}                   {% if paginator. total_pages &gt; 1 %}              {% if paginator. previous_page %}        &laquo; Prev       {% else %}        &laquo;       {% endif %}       {% for page in (1. . paginator. total_pages) %}        {% if page == paginator. page %}        {{ page }}        {% elsif page == 1 %}        {{ page }}        {% else %}        {{ page }}        {% endif %}       {% endfor %}       {% if paginator. next_page %}        Next &raquo;       {% else %}        &raquo;       {% endif %}            {% endif %}                     {% include sidebar-featured. html %}      "
    }, {
    "id": 3,
    "url": "/robots.txt",
    "title": "",
    "body": "      Sitemap: {{ “sitemap. xml”   absolute_url }}   "
    }, {
    "id": 4,
    "url": "/pri3d/",
    "title": "Pri3D: Can 3D Priors Help 2D Representation Learning?",
    "body": "2021/08/29 -   Pri3D leverages 3D priors for downstream 2D image understanding tasks: during pre-training, we incorporate view-invariant and geometric priors from color-geometry information given by RGB-D datasets, imbuing geometric priors into learned features. We show that these 3D-imbued learned features can effectively transfer to improved performance on 2D tasks such as semantic segmentation, object detection, and instance segmentation. Abstract:  Recent advances in 3D perception have shown impressive progress in understanding geometric structures of 3D shapes and even scenes. Inspired by these advances in geometric understanding, we aim to imbue image-based perception with representations learned under geometric constraints. We introduce an approach to learn view-invariant, geometry-aware representations for network pre-training, based on multi-view RGB-D data, that can then be effectively transferred to downstream 2D tasks. We propose to employ contrastive learning under both multi-view image constraints and image-geometry constraints to encode 3D priors into learned 2D representations. This results not only in improvement over 2D-only representation learning on the image-based tasks of semantic segmentation, instance segmentation and object detection on real-world indoor datasets, but moreover, provides significant improvement in the low data regime. We show significant improvement of 6. 0% on semantic segmentation on full data as well as 11. 9% on 20% data against baselines on ScanNet. Introduction: In recent years, we have seen rapid progress in learning-based approaches for semantic understanding of 3D scenes, particularly in the tasks of 3D semantic segmentation, 3D object detection, and 3D semantic instance segmentation. Such approaches leverage geometric observations, exploiting the representation of points, voxels, or meshes to obtain accurate 3D semantics. These have shown significant promise towards realizing applications such as depth-based scene understanding for robotics, as well as augmented or virtual reality. In parallel to the development of such methods, the availability of large-scale RGB-D datasets has further accelerated the research area. One advantage of learning directly in 3D in contrast to learning solely from 2D images is that methods operate in metric 3D space; hence, it is not necessary to learn view-dependent effects and/or projective mappings. This allows training 3D neural networks from scratch in a relatively short time frame and typically requires a (relatively) small number of training samples; e. g. state-of-the-art 3D neural networks can be trained with around 1000 scenes from ScanNet. Our main idea is to leverage these advantages in the form of 3D priors for image-based scene understanding. Simultaneously, we have seen tremendous progress on representation learning in the image domain, mostly powered by the success of recent contrastive learning based methods. The exploration in 2D representation learning heavily relies on the paradigm of instance discrimination, where different augmented copies of the same instance are drawn closer. Different invariances can be encoded from those low-level augmentations such as random cropping, flipping and scaling, as well as color jittering. However, despite the common belief that 3D view invariance is an essential property for a capable visual system, there remains little study linking the 3D priors and 2D representation learning. The goal of our work is to explore the combination of contrastive representation learning with 3D priors, and offer some preliminary evidence towards answering an important question: can 3D priors help 2D representation learning? To this end, we introduce Pri3D, which aims to learn with 3D priors in a pre-training stage and subsequently use them as initialization for fine-tuning on image-based downstream tasks such as semantic segmentation, detection, and instance segmentation. More specifically, we introduce geometric constraints to a contrastive learning scheme, which are enabled by multi-view RGB-D data that is readily available. We propose to exploit geometric correlations implicit multi-view constraints between different images through the correspondence of pixels which correspond to the same geometry, as well as explicit correspondence of geometric patches which correspond to image regions. This imbues geometric knowledge into the learned representations of the image inputs which can then be leveraged as pre-trained features for various image-based vision tasks, particularly in the low training data regime. We demonstrate our approach by pre-training on ScanNet under these geometric constraints for representation learning, and show that such self-supervised pre-training (i. e. , no semantic labels are used) results in improved performance of 2D semantic segmentation, instance segmentation and detection tasks. We demonstrate this not only on ScanNet data, but also generalizing to improved performance on NYUv2 semantic segmentation, instance segmentation and detection tasks. Moreover, leveraging such geometric priors for pre-training provides robust features which can consistently improve performance under a wide range of amount of training data available. While we focus on indoor scene understanding in this paper, we believe our results can shed light on the paradigm of representation learning with 3D priors and open new opportunities towards more general 3D-aware image understanding.   Method Overview. During pre-training, we use geometric constraints from RGB-D reconstructions to learn 3D priors for image-based representations. Specifically, we propose a contrastive learning formulation that models multi-view correspondences (View-Invariant Contrastive Loss) as well as geometry-to-image alignments (Geometric Prior Contrastive Loss). Our Pri3D pre-training strategy embeds geometric priors into the learned representations (in a form of pre-trained 2D convolutional network weights) that can be further leveraged for downstream 2D-only image understanding tasks. Learning Representations from 3D Priors: In this section, we introduce Pri3D: our key idea is to leverage constraints from RGB-D reconstructions, now readily available in various datasets, to embed 3D priors in image-based representations. From a dataset of RGB-D sequences, each sequence consists of depth and color frames, ${D_i}$ and ${C_i}$, respectively, as well as automatically-computed 6-DoF camera pose alignments ${T_i}$ (mapping from each camera space to world space) from state-of-the-art SLAM, all resulting in a reconstructed 3D surface geometry $S$. Specifically, we observe that multi-view constraints can be exploited in order to learn view-invariance without the need of costly semantic labels. In addition, we learn features through geometric representations given by the obtained geometry in RGB-D scans, again, without the need of human annotations. For both, we use state-of-the-art contrastive learning in order to constrain the multi-modal input for training. We show that these priors can be embedded in the image-based representations such that the learned features can be used as pre-trained features for purely image-based perception tasks; i. e. , we can perform tasks such as image segmentation or instance segmentation on a single RGB image. An overview approach is shown in Figure 2. View-Invariant Learning: In 2D contrastive pre-training algorithms, a variety of data augmentations are used for finding positive matching pairs, such as MoCo and SimCLR. For instance, they use the random crops as self-supervised constraints within the same image for positive pairs, and correspondences to crops from other images as negative pairs. Our key idea is that with the availability of 3D data for training, we can leverage geometric knowledge to provide matching constraints between multiple images that see the same points. To this end, we use the ScanNet RGB-D dataset which provides a sequence of RGB-D images with camera poses computed by a state-of-the-art SLAM method, and reconstructed surface geometry $S$. Note that both the pose alignments and the 3D reconstructions were obtained in a fully-automated fashion without any user input. For a given RGB-D sequence in the train set, our method then leverages the 3D data to finding pixel-level correspondences between 2D frames. We consider all pairs of frames $(i,j)$ from the RGB-D sequence. We then back-project frame $i$’s depth map $D_i$ to camera space, and transform the points into the world space by $T_i$. The depth values of frame $j$ are similarly transformed into world space. Pixel correspondences between the two frames are then determined as those whose 3D world locations like within 2cm of each other. We use the pairs of frames which have at least 30% overlap, with overlap computed as number of corresponding pixels in both frames divided by total number of points in the two frames. In total, we sample around 840k pairs of images from the ScanNet training data. In the training phase, a pair of sampled images is input to a shared 2D network backbone. In our experiments, we use a UNet-style backbone with ResNet architecture as an encoder, but note that our method is agnostic to the underlying encoder backbone. We then consider the feature map from decoder of the 2D backbone, where its size is half of the input resolution. For each image in the pair, we use the aforementioned pixel-to-pixel correspondences which refer to the same physical 3D point. Note that these correspondences may have different color values due to view-dependent lighting effects but represent the same 3D world location; additionally, the regions surrounding the correspondences appear different due to different viewing angles. In this fashion, we treat these pairs of correspondences as positive samples in contrastive learning; we use all non-matching pixels as negatives. Non-matching pixels are also defined within the set of correspondences. For a pair of frames with $n$ pairs of correspondences as positive samples, we use all $n(n-1)$ negative pairs (each of $n$ pixels from the first frame with each $n-1$ non-matching pixel from the second). Non-matching pixel-voxels are defined similarly but from a pair of frame and 3D chunk. Between the features of matching and non-matching pixel locations, we then compute a PointInfoNCE loss, which is defined as: \(L_p = -\sum_{(a,b) \in M}\log{\frac{\exp(f_a \cdot f_b / \tau)}{\sum_{(\cdot,k) \in M}\exp(f_a \cdot f_k /\tau)}}\), where $M$ is the set of pairs of pixel correspondences, ahd $f$ represents the associated feature vector of a pixel in the feature map. By leveraging multi-view correspondences, e apply implicit 3D priors-without any explicit 3D learning, we imbue view-invariance in the learned image-based features. Geometric Prior: In addition to multi-view constraints, we also leverage explicit geometry-color correspondences inherent to the RGB-D data during training. For an RGB-D train sequence, the geometry-color correspondences are given by associating the surface reconstruction $S$ with the RGB frames of the sequence. For each frame $i$, we compute its view frustum in the world space. A volumetric chuck $V_i$ of $S$ is then cropped from the axis-aligned bounding box of the view frustum. We represent $V_i$ as a 2cm resolution volumetric occupancy grid from the surface. We thus consider pairs of color frames and geometric chuncks $(C_i, V_i)$. From the color-geometry pairs $(C_i, V_i)$, we compute pixel-voxel correspondences by projecting the depth values for each pixel in the corresponding frame $D_i$ into world space to find an associated occupied voxel in $V_i$ that lies within 2cm of the 3D location of the pixel. During training, we leverage the color-geometry correspondences with a 2D network backbone and a 3D network backbone. We use a UNet-style architecture with ResNet encoder for the 2D network backbone, and a UNet-sytle sparse convolutional 3D network backbone. Similarly to view-invariant training, we also take the output from the decoder of the 2D network backbone where its output size is half the input resolution. We then use the pixel-voxel correspondences in $(C_i, V_i)$ for contrastive learning, with positives as all matching pixel-voxel pairs and negatives as all non-matching pixel-voxel pairs. We apply the PointInfoNCE loss with $f_i$ as the 2D feature of a pixel, and $f_j$ is the feature vector from its 3D correspondence, and $M$ the set of 2D-3D pixel-voxel correspondences pairs. Joint Learning: We can leverage not only the view-invariant constraints and geometric priors during training, but also learn jointly from the combination of both constraints. We can thus employ a shared 2D network backbone and a 3D network backbone, with the 2D network backbone constrained by both view-invariant constraints and as the 2D part of geometric prior constraint. During training, we consider $(C_i, C_j, V_i, V_j)$ of overlapping color frames $C_i$ and $C_j$ as well as $V_i$ and $V_j$ which have geometric correspondence with $C_i$, $C_j$ respectively. The shared 2D network backbone then processes $C_i$, $C_j$ and computes the view-invariant loss from Section 3. 1. At the same time, $V_i$ and $V_j$ are processed by the 3D sparse convolutional backbone, with the loss relative to the features of $C_i$ and $C_j$ respectively. This embeds both constraints into the learned 2D representation. "
    }, {
    "id": 5,
    "url": "/random-rooms/",
    "title": "RandomRooms: Unsupervised Pre-training from Synthetic Shapes and ",
    "body": "2021/08/27 - Abstract:  3D point cloud understanding has made great progress in recent years. However, one major bottleneck is the scarcity of annotated real datasets, especially compared to 2D object detection tasks, since a large amount of labor is involved in annotating the real scans of a scene. A promising solution to this problem is to make better use of the synthetic dataset, which consists of CAD object models, to boost the learning on real datasets. This can be achieved by the pre-training and fine-tuning procedure. However, recent work on 3D pre-training exhibits failure when transfer features learned on synthetic objects to other real-world applications. In this work, we put forward a new method called RandomRooms to accomplish this objective. In particular, we propose to generate random layouts of a scene by making use of the objects in the synthetic CAD dataset and learn the 3D scene representation by applying object-level contrastive learning on two random scenes generated from the same set of synthetic objects. The model pre-trained in this way can serve as a better initialization when later fine-tuning on the 3D object detection task. Empirically, we show consistent improvement in downstream 3D detection tasks on several base models, especially when less training data are used, which strongly demonstrates the effectiveness and generalization of our method. Benefiting from the rich semantic knowledge and diverse objects from synthetic data, our method establishes the new state-of-the-art on widely-used 3D detection benchmarks ScanNetV2 and SUN RGB-D. We expect our attempt to provide a new perspective for bridging object and scene-level 3D understanding.   The main idea of RandomRooms. To generate two different layouts, we randomly place the same set of objects sampled from synthetic datasts in rectangular rooms. With the proposed object-level contrastive learning, models pretrained on these pseudo scenes can serve as a better initialization for downstream 3D object detection task. Introduction: Recent years have witnessed great progress in 3D deep learning, especially on 3D point clouds. With the emergence of powerful models, we are now able to make significant breakthroughs on many point cloud tasks, ranging from object-level understanding ones to scene-level understanding ones, such as 3D object detection and 3D semantic segmentation. These scene-level tasks are considered to be more complicated and more important as they often require higher level understanding compared to object level tasks like shape classification. One of the most important tasks for 3D point cloud scene understanding is the 3D object detection, which aims at localizing the objects of interest in the point cloud of the scene and telling the category they belong to. However, one major bottleneck that hinders the researchers from moving forward is the lack of large-scale real datasets, considering the difficulty in collecting and labeling high-quality 3D scene data. Compared to 2D object detection task where we have large annotated real datasets COCO, the real datasets here we use for 3D object detection task are much smaller in scales, and generating a synthesized scene dataset also involves a heavy workload in modeling and rendering. A preferred solution is to utilize synthetic CAD object models to help the learning of 3D object detector since it is much easier to access such type of data. Considering we have no annotation of bounding box for synthetic CAD data, this idea can be achieved in a similar way as the unsupervised pre-training for 2D vision takss where we first pretrain on a large-scale dataset in an unsupervised manner and then fine-tune on a smaller annotated dataset. Yet, most previous works focus on the pretraining for single object level tasks, such as reconstruction, shape classification or part segmentation, or on some low-level tasks like registration. A recent work, namely PointContrast, first explores the possibility of pre-training in the context of 3D representation learning for higher level scene understanding tasks, i. e. 3D detection and segmentation. Nevertheless, they conduct the pre-training on the real scene dataset and provide a failure case when pre-training the backbone model on ShapeNet, which consists of synthetic CAD object models. They attribute this unsuccessful attempt to two reasons, that is, the domain gap between real and synthetic data as well as the insufficiency of capturing point-level representation by directly training on single objects. Despite these difficulties, it is still desirable to make the ShapeNet play the role of ImageNet in 2D vision since it is easy to obtain a large number of synthetic CAD models. In this work, we put forward a new framework to show the possibility of using a synthetic CAD model dataset, i. e. ShapeNet, for the 3D pre-training before fine-tuning on downstream 3D object detection task. To this end, we propose a method named RandomRoom. In particular, we propose to generate two different layouts using one set of objects which are randomly sampled out of the ShapeNet dataset. Having these two scenes that are made up of the same set of objects, we can then perform the contrastive learning at the object level to learn the 3D scene representation. Different from PointContrast where the contrastive learning is performed at the point level, our approach has two advantages. One is to remove the requirement of point correspondence between two views, which is indispensable in PointContrast given that it is necessary to exploit such information to obtain positive and negative pairs for the contrastive learning. This requirement limits the applications of PointContrast, since the CAD model datasets like ShapeNet and many other real-world datasets like SUN RGB-D cannot provide such information. The other advantage is that our method can support more diverse backbone models. Most state-of-the-art models on tasks like 3D object detection apply PointNet++ style models as their backbone, and replacing it with Sparse Res-UNet may lead to the drop of accuracy, according to the PointContrast. However, PointContrast cannot well support the pre-training of PointNet++ style model as the UNet-like models, since the point correspondence may be missing after each abstraction level in PointNet++. With the proposed RandomRoom, we are enabled to perform contrastive learning at the level of objects and thus better support the pretraining of PointNet++ like models as we no longer need to keep the point correspondence for contrastive learning like PointContrast. Our method is straightforward yet effective. We conduct the experiments on the 3D object detection task where only the geometric information is available for input as the models in CAD datasets do not carry color information. The results of empirical study strongly demonstrate the effectiveness of our method. In particular, we achieve the state-of-the-art of 3D object detection on two widely used benchmarks, ScanNetV2 and SUN-RGBD. Furthermore, our method can achieve even more improvements when much less training samples are used, demonstrating that our model can learn a better initialization for 3D object detection.  RandomRooms: In this section, we describe the details of the proposed RandomRooms method. We first briefly review existing contrastive representation learning methods and illustrate the intuition of our method in Section 3. 1. Then, we describe how to use synthetic objects to construct random rooms in 3. 2. In Section 3. 3, we show our pretrain task for learning scene level representation from the pseudo scenes. The overview of our framework is represented in Figure 2. Overview of Contrastive Learning: We begin by reviewing the existing contrastive representation learning methods for 2D and 3D understanding to illustrate the motivation of our method. Contrastive learning is at the core of several recent methods on unsupervised learning, which exhibits promising performance on both 2D and 3D tasks and shows impressive generalization ability as a new type of pre-training method for various downstream tasks. The key ingredient of contrastive learning is constructing positive and negative pairs to learn discriminative representation, which inherits the idea of conventional contrastive learning in metric learning literature. Given an input $x$ and its positive pair $x_{+}$ and a set of negative examples ${x_i}$, a commonly used training objective for contrastive representation learning is based on InfoNCE: \(L_{contrastive} = -log{\frac{\exp(\phi(x) \cdot \phi(x_{+})/\tau)}{\sum_i \exp(\phi(x) \cdot \phi(x_i)/\tau)}}\) where $\phi$ is the encoder network that maps the input to a feature vector and $\tau$ is a temperature hyper-parameter. Intuitively, the contrastive learning methods supervise models by encouraging the features of the different views of the same sample to be close to each other and distinguishable from other samples. Hence the quality of positive pairs and negative examples is a critical factor is a critical factor to learn the encoder. Since category annotations are not available in the unsupervised learning scenario, a common practice is using different augmentations of an input as the positive pairs and treating all other samples as negative samples. Although this design has proven to be effective in image representation learning, we argue there is a better solution to construct positive pairs for 3D understanding. One fundamental difference between 2D and 3D data is that the spatial structures of pixels do not reflect the actual geometric structures of the objects, but the spatial structures in 3D data always faithfully illustrate the layouts in the real world. This property suggests that it may be easier to manipulate or augment 3D data compared to 2D images. Inspired by the rendering techniques in computer graphics, we propose to generate positive pairs of 3D scenes by randomly manipulating the layouts of 3D objects in a scene. Since we only need 3D objects instead of the whole scene in this process, our method makes it possible to use 3D object models to promote scene level representation learning. It is worth noting that a recent work, namely PointContrast, explores 3D contrastive representation learnign by using 3D point clouds from different views as the positive pair, where a point level contrastive loss is designed. This method is baed on the multi-view point cloud sequences provided in ScanNetV2. Instead, our method focuses on leveraging object level 3D data, which are easier to collect and have more diverse categories. Random Rooms from Synthetic Objects: Compared to ScanNetV2, which contains ~15k objects from 17 categories, synthetic shape datasets like ShapeNet provide a more plentiful source for 3D understanding. For example, ShapeNetCore contains ~52k objects from 55 categories. Therefore, the primary goal of this paper is to study how to use synthetic CAD models collected by ShapeNet to improve downstream tasks like 3D detection and segmentation on real-world datasets. Previous work shows that directly pre-training on ShapeNet will not yield performance improvement on downstream detection and segmentation task. We suspect the main reason is the domain gap between the single object classification taks on ShapeNet and the multiple objects localization task on real-world datsets. In order to bridge the gap, we propose to generate pseudo scenes (we name them random rooms) from synthetic objects to construct the training data that are helpful ofr scene level understanding. Given a set of randomly sampled objects, we generate a random room following the three steps:    Object Augmentation: We first resize the object to a random size in $[0. 5m, 2. 0m]$ to ensure the objects have similar sizes as objects in ScanNetV2. Then, we apply commonly used object point cloud augmentation techniques including rotation, point dropping, and jittering.     Layout Generation: For the ease of implementation, we place objects in a rectangular room. The size of the room is adaptively adjusted according to the overall area of the augmented objects. The layout is generated based on two simple principles: 1) non-overlapping: any two objects should not occupy the same space in the room; 2) gravity: objects should not float in the air, and larger objects should not be placed over the smaller ones. In turn, we place objects in the descending order of the area. Insired by Tetris, for each object, we first randomly choose a position in the X-Y plane that satisfies the above principles, then determine the location (the Z value) based on the current maximum height of the position. The object will not be placed in a position if the current maximum height of the position exceeds 2m.     Scene Augmentation: Lastly, we apply data augmentation like rotation along the $Z$ axis, point dropping, jittering to the whole scene. To make the generated scenes more similar to the real scenes, we also add the floor and walls as confounders.  Some examples of the random rooms are illustrated in Figure 6. Representation Learning from Random Rooms: To utilize the generated random rooms, we devise an object-level contrastive learning (OCL) method, which learns discriminative representation without category annotations. Givene $n$ randomly sampled objects $\{ x_1, x_2, \dots, x_n \}$, we first generate two random rooms $R_A = \{x^A_1, x^A_2, \dots, x^A_n\}$ and $R_B = \{x^B_1, x^B_2, \dots, x^B_n\}$ by conducting the above mentioned steps individually. Then we employ the point cloud encoder-decoder network $\mathcal{M}$ (e. g. PointNet++ with feature propagation layers) to extract per-point features of the two scenes $F_A = \mathcal{M}(R_A)$ and $F_B = \mathcal{M}(R_B)$. Since the random room is constructed by several individual objects, the instance labels can be naturally defined. The goal of object-level contrastive learning is to exploit instance labels as a source of free and plentiful supervisory signals for training a rich representation for point cloud understanding. To obtain the feature of each object, we apply the average pooling operation $\mathcal{A}$ on per-point features belonging to this object: \(\begin{split} \\{h^A_1, h^A_2, \dots, h^A_n\\} = \mathcal{A}(F_A), \\ \\{h^B_1, h^B_2, \dots, h^B_n\\} = \mathcal{A}(F_B) \end{split}\). Similar to the common practice in contrastive learning, the object features are projected onto a unit hypersphere using a multi-layer perceptron network (MLP) followed by L2 normalization. The object-level contrastive learning objective can be written as \(L_{OCL} = - \frac{1}{n}\sum_{i=1}^n \log{\frac{\exp(f^A_i \cdot f^B_i /\tau)}{\sum_{f \in \mathcal{F} \exp(f^A_i \cdot f/\tau)}}} - \frac{1}{n}\sum_{i=1}^n \log{\frac{\exp(f^B_i \cdot f^A_i /\tau)}{\sum_{f \in \mathcal{F} \exp(f^B_i \cdot f/\tau)}}}\), where $f_i^A = \phi(h_i^A)$ and $f_i^B = \phi(h_i^B)$ are the projected features of the $i$-th object in $R_A$ and $R_B$ respectively, $\phi$ is the projection head and $\mathcal{F}$ is the set of all projected features in the batch. Note that compared to point-level contrastive learning task in PointContrast, our method further utilizes the instance-level knowledge thanks to the generation mechanism of RandomRooms. We argue that objec-level contrastive learning introduces more semantic knowledge and can be more helpful for downstream localization tasks.  Experiments: One primary goal of representation learning is to learn the representation that can transfer to downstream tasks. To apply our RandomRooms method to scene level understanding taks like 3D object detection, we adopt the unsupervised pre-training + supervised fine-tuning pipeline. Specifically, we first pre-train the backbone model on ShapeNet using our method, then we use the pre-trained weights as the initialization and further fine-tune the model on the downstream 3D object detection task. Pre-training Setups: We perform the pre-training on ShapeNet, a dataset composed of richly-annotated shapes represented by 3D CAD models of objects from 55 common categories. To generate the random room, we first need to randomly sample multiple objects from the dataset. The number of objects we sample is a random integer from 12 to 18, which is similar to the average number of objects in ScanNetV2 scenes. Then for each sampled object, we perform the random room generation algorithm mentioned in Section 3. 2. The object-level contrastive learning loss is used to train the model in an unsupervised manner. For the downstream 3D object detection task, we use the backbone model which take as input 40,000 points. Following the network configurations in these two works, we use the 1024-point feature as the output of the backbone models and perform contrastive learning one this feature. During pre-training, we use the Adam optimizer with initial learning 0. 001. We train the model for 300 epochs and the learning rate is multiplied by 0. 1 at the 100-th and 200-th epoch. The batch size is set to 16 such that roughly 200~300 unique objects are involved in the contrastive learning at every iteration. "
    }, {
    "id": 6,
    "url": "/welcome-to-jekyll/",
    "title": "Welcome to Jekyll!",
    "body": "2019/02/04 - \[x^2 + y^2 = 2\]You’ll find this post in your _posts directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run jekyll serve, which launches a web server and auto-regenerates your site when a file is updated. To add new posts, simply add a file in the _posts directory that follows the convention YYYY-MM-DD-name-of-post. ext and includes the necessary front matter. Take a look at the source for this post to get an idea about how it works. \(x^2 + y^2 = 2\)Jekyll also offers powerful support for code snippets: {% highlight ruby %}def print_hi(name) puts “Hi, #{name}”endprint_hi(‘Tom’)#=&gt; prints ‘Hi, Tom’ to STDOUT. {% endhighlight %} Check out the Jekyll docs for more info on how to get the most out of Jekyll. File all bugs/feature requests at Jekyll’s GitHub repo. If you have questions, you can ask them on Jekyll Talk. "
    }, {
    "id": 7,
    "url": "/powerful-things-markdown-editor/",
    "title": "Powerful things you can do with the Markdown editor",
    "body": "2019/02/03 - There are lots of powerful things you can do with the Markdown editor. If you’ve gotten pretty comfortable with writing in Markdown, then you may enjoy some more advanced tips about the types of things you can do with Markdown! As with the last post about the editor, you’ll want to be actually editing this post as you read it so that you can see all the Markdown code we’re using. Special formatting: As well as bold and italics, you can also use some other special formatting in Markdown when the need arises, for example:  strike through ==highlight== *escaped characters*Writing code blocks: There are two types of code elements which can be inserted in Markdown, the first is inline, and the other is block. Inline code is formatted by wrapping any word or words in back-ticks, like this. Larger snippets of code can be displayed across multiple lines using triple back ticks: . my-link {  text-decoration: underline;}If you want to get really fancy, you can even add syntax highlighting using Rouge.  Reference lists: The quick brown jumped over the lazy. Another way to insert links in markdown is using reference lists. You might want to use this style of linking to cite reference material in a Wikipedia-style. All of the links are listed at the end of the document, so you can maintain full separation between content and its source or reference. Full HTML: Perhaps the best part of Markdown is that you’re never limited to just Markdown. You can write HTML directly in the Markdown editor and it will just work as HTML usually does. No limits! Here’s a standard YouTube embed code as an example: "
    }, {
    "id": 8,
    "url": "/first-mass-produced/",
    "title": "The first mass-produced book to deviate from a rectilinear format",
    "body": "2019/02/02 - The first mass-produced book to deviate from a rectilinear format, at least in the United States, is thought to be this 1863 edition of Red Riding Hood, cut into the shape of the protagonist herself with the troublesome wolf curled at her feet. Produced by the Boston-based publisher Louis Prang, this is the first in their “Doll Series”, a set of five “die-cut” books, known also as shape books — the other titles being Robinson Crusoe, Goody Two-Shoes (also written by Red Riding Hood author Lydia Very), Cinderella, and King Winter. An 1868 Prang catalogue would later claim that such “books in the shape of a regular paper Doll… originated with us”.  It would seem the claim could also extend to die cut books in general, as we can’t find anything sooner, but do let us know in the comments if you have further light to shed on this! Such books are, of course, still popular in children’s publishing today, though the die cutting is not now limited to mere outlines, as evidenced in a beautiful 2014 version of the same Little Red Riding Hood story. The die cut has also been employed in the non-juvenile sphere as well, a recent example being Jonathan Safran Foer’s ambitious Tree of Codes. As for this particular rendition of Charles Perrault’s classic tale, the text and design is by Lydia Very (1823-1901), sister of Transcendentalist poet Jones Very. The gruesome ending of the original - which sees Little Red Riding Hood being gobbled up as well as her grandmother - is avoided here, the gore giving way to the less bloody aims of the morality tale, and the lesson that one should not disobey one’s mother. To deviate from a rectilinear format, at least in the United States, is thought to be this 1863 edition of Red Riding Hood, cut into the shape of the protagonist herself with the troublesome wolf curled at her feet. Produced by the Boston-based publisher Louis Prang, this is the first in their “Doll Series”, a set of five “die-cut” books, known also as shape books — the other titles being Robinson Crusoe, Goody Two-Shoes (also written by Red Riding Hood author Lydia Very), Cinderella, and King Winter. An 1868 Prang catalogue would later claim that such “books in the shape of a regular paper Doll… originated with us”.  The claim could also extend to die cut books in general, as we can’t find anything sooner, but do let us know in the comments if you have further light to shed on this! Such books are, of course, still popular in children’s publishing today, though the die cutting is not now limited to mere outlines, as evidenced in a beautiful 2014 version of the same Little Red Riding Hood story. The die cut has also been employed in the non-juvenile sphere as well, a recent example being Jonathan Safran Foer’s ambitious Tree of Codes. As for this particular rendition of Charles Perrault’s classic tale, the text and design is by Lydia Very (1823-1901), sister of Transcendentalist poet Jones Very. The gruesome ending of the original - which sees Little Red Riding Hood being gobbled up as well as her grandmother - is avoided here, the gore giving way to the less bloody aims of the morality tale, and the lesson that one should not disobey one’s mother. "
    }, {
    "id": 9,
    "url": "/education/",
    "title": "Education must also train one for quick, resolute and effective thinking.",
    "body": "2019/02/01 - There are lots of powerful things you can do with the Markdown editor If you’ve gotten pretty comfortable with writing in Markdown, then you may enjoy some more advanced tips about the types of things you can do with Markdown! As with the last post about the editor, you’ll want to be actually editing this post as you read it so that you can see all the Markdown code we’re using. Special formatting: As well as bold and italics, you can also use some other special formatting in Markdown when the need arises, for example:  strike through ==highlight== *escaped characters*Writing code blocks: There are two types of code elements which can be inserted in Markdown, the first is inline, and the other is block. Inline code is formatted by wrapping any word or words in back-ticks, like this. Larger snippets of code can be displayed across multiple lines using triple back ticks: . my-link {  text-decoration: underline;}If you want to get really fancy, you can even add syntax highlighting using Rouge.  Reference lists: The quick brown jumped over the lazy. Another way to insert links in markdown is using reference lists. You might want to use this style of linking to cite reference material in a Wikipedia-style. All of the links are listed at the end of the document, so you can maintain full separation between content and its source or reference. Full HTML: Perhaps the best part of Markdown is that you’re never limited to just Markdown. You can write HTML directly in the Markdown editor and it will just work as HTML usually does. No limits! Here’s a standard YouTube embed code as an example: "
    }, {
    "id": 10,
    "url": "/acumulated-experience/",
    "title": "Accumulated experience of social living",
    "body": "2019/01/30 - The die cut has also been employed in the non-juvenile sphere as well, a recent example being Jonathan Safran Foer’s ambitious Tree of Codes. As for this particular rendition of Charles Perrault’s classic tale, the text and design is by Lydia Very (1823-1901), sister of Transcendentalist poet Jones Very. The gruesome ending of the original - which sees Little Red Riding Hood being gobbled up as well as her grandmother - is avoided here, the gore giving way to the less bloody aims of the morality tale, and the lesson that one should not disobey one’s mother. The first mass-produced book to deviate from a rectilinear format, at least in the United States, is thought to be this 1863 edition of Red Riding Hood, cut into the shape of the protagonist herself with the troublesome wolf curled at her feet. Produced by the Boston-based publisher Louis Prang, this is the first in their “Doll Series”, a set of five “die-cut” books, known also as shape books — the other titles being Robinson Crusoe, Goody Two-Shoes (also written by Red Riding Hood author Lydia Very), Cinderella, and King Winter. An 1868 Prang catalogue would later claim that such “books in the shape of a regular paper Doll… originated with us”.  It would seem the claim could also extend to die cut books in general, as we can’t find anything sooner, but do let us know in the comments if you have further light to shed on this! Such books are, of course, still popular in children’s publishing today, though the die cutting is not now limited to mere outlines, as evidenced in a beautiful 2014 version of the same Little Red Riding Hood story. "
    }, {
    "id": 11,
    "url": "/about-bundler/",
    "title": "About Bundler",
    "body": "2019/01/29 - gem install bundler installs the bundler gem through RubyGems. You only need to install it once - not every time you create a new Jekyll project. Here are some additional details: bundler is a gem that manages other Ruby gems. It makes sure your gems and gem versions are compatible, and that you have all necessary dependencies each gem requires. The Gemfile and Gemfile. lock files inform Bundler about the gem requirements in your site. If your site doesn’t have these Gemfiles, you can omit bundle exec and just run jekyll serve. When you run bundle exec jekyll serve, Bundler uses the gems and versions as specified in Gemfile. lock to ensure your Jekyll site builds with no compatibility or dependency conflicts. For more information about how to use Bundler in your Jekyll project, this tutorial should provide answers to the most common questions and explain how to get up and running quickly. "
    }, {
    "id": 12,
    "url": "/we-all-wait-for-summer/",
    "title": "We all wait for summer",
    "body": "2019/01/28 - This is changed. As I engage in the so-called “bull sessions” around and about the school, I too often find that most college men have a misconception of the purpose of education. Most of the “brethren” think that education should equip them with the proper instruments of exploitation so that they can forever trample over the masses. Still others think that education should furnish them with noble ends rather than means to an end. It seems to me that education has a two-fold function to perform in the life of man and in society: the one is utility and the other is culture. Education must enable a man to become more efficient, to achieve with increasing facility the ligitimate goals of his life. "
    }, {
    "id": 13,
    "url": "/tree-of-codes/",
    "title": "Tree of Codes",
    "body": "2019/01/27 - The first mass-produced book to deviate from a rectilinear format, at least in the United States, is thought to be this 1863 edition of Red Riding Hood, cut into the shape of the protagonist herself with the troublesome wolf curled at her feet. Produced by the Boston-based publisher Louis Prang, this is the first in their “Doll Series”, a set of five “die-cut” books, known also as shape books — the other titles being Robinson Crusoe, Goody Two-Shoes (also written by Red Riding Hood author Lydia Very), Cinderella, and King Winter. As for this particular rendition of Charles Perrault’s classic tale, the text and design is by Lydia Very (1823-1901), sister of Transcendentalist poet Jones Very. The gruesome ending of the original — which sees Little Red Riding Hood being gobbled up as well as her grandmother — is avoided here, the gore giving way to the less bloody aims of the morality tale, and the lesson that one should not disobey one’s mother.  It would seem the claim could also extend to die cut books in general, as we can’t find anything sooner, but do let us know in the comments if you have further light to shed on this! Such books are, of course, still popular in children’s publishing today, though the die cutting is not now limited to mere outlines, as evidenced in a beautiful 2014 version of the same Little Red Riding Hood story. An 1868 Prang catalogue would later claim that such “books in the shape of a regular paper Doll… originated with us”. The die cut has also been employed in the non-juvenile sphere as well, a recent example being Jonathan Safran Foer’s ambitious Tree of Codes. "
    }, {
    "id": 14,
    "url": "/red-riding/",
    "title": "Red Riding Hood",
    "body": "2019/01/26 - The first mass-produced book to deviate from a rectilinear format, at least in the United States, is thought to be this 1863 edition of Red Riding Hood, cut into the shape of the protagonist herself with the troublesome wolf curled at her feet. Produced by the Boston-based publisher Louis Prang, this is the first in their “Doll Series”, a set of five “die-cut” books, known also as shape books — the other titles being Robinson Crusoe, Goody Two-Shoes (also written by Red Riding Hood author Lydia Very), Cinderella, and King Winter. An 1868 Prang catalogue would later claim that such “books in the shape of a regular paper Doll… originated with us”.  It would seem the claim could also extend to die cut books in general, as we can’t find anything sooner, but do let us know in the comments if you have further light to shed on this! Such books are, of course, still popular in children’s publishing today, though the die cutting is not now limited to mere outlines, as evidenced in a beautiful 2014 version of the same Little Red Riding Hood story. The die cut has also been employed in the non-juvenile sphere as well, a recent example being Jonathan Safran Foer’s ambitious Tree of Codes. As for this particular rendition of Charles Perrault’s classic tale, the text and design is by Lydia Very (1823-1901), sister of Transcendentalist poet Jones Very. The gruesome ending of the original — which sees Little Red Riding Hood being gobbled up as well as her grandmother — is avoided here, the gore giving way to the less bloody aims of the morality tale, and the lesson that one should not disobey one’s mother. "
    }, {
    "id": 15,
    "url": "/press-and-education/",
    "title": "Press and education",
    "body": "2019/01/25 - Even the press, the classroom, the platform, and the pulpit in many instances do not give us objective and unbiased truths. To save man from the morass of propaganda, in my opinion, is one of the chief aims of education. Education must enable one to sift and weigh evidence, to discern the true from the false, the real from the unreal, and the facts from the fiction. Education must also train one for quick, resolute and effective thinking. To think incisively and to think for one’s self is very difficult.  We are prone to let our mental life become invaded by legions of half truths, prejudices, and propaganda. At this point, I often wonder whether or not education is fulfilling its purpose. A great majority of the so-called educated people do not think logically and scientifically. The function of education, therefore, is to teach one to think intensively and to think critically. But education which stops with efficiency may prove the greatest menace to society. The most dangerous criminal may be the man gifted with reason, but with no morals. The late Eugene Talmadge, in my opinion, possessed one of the better minds of Georgia, or even America. Moreover, he wore the Phi Beta Kappa key. By all measuring rods, Mr. Talmadge could think critically and intensively; yet he contends that I am an inferior being. Are those the types of men we call educated? We must remember that intelligence is not enough. Intelligence plus character–that is the goal of true education. The complete education gives one not only power of concentration, but worthy objectives upon which to concentrate. The broad education will, therefore, transmit to one not only the accumulated knowledge of the race but also the accumulated experience of social living. "
    }, {
    "id": 16,
    "url": "/powerful-things-markdown-editor/",
    "title": "Powerful things you can do with the Markdown editor",
    "body": "2019/01/24 - There are lots of powerful things you can do with the Markdown editor If you’ve gotten pretty comfortable with writing in Markdown, then you may enjoy some more advanced tips about the types of things you can do with Markdown! As with the last post about the editor, you’ll want to be actually editing this post as you read it so that you can see all the Markdown code we’re using. Special formatting: As well as bold and italics, you can also use some other special formatting in Markdown when the need arises, for example:  strike through ==highlight== *escaped characters*Writing code blocks: There are two types of code elements which can be inserted in Markdown, the first is inline, and the other is block. Inline code is formatted by wrapping any word or words in back-ticks, like this. Larger snippets of code can be displayed across multiple lines using triple back ticks: . my-link {  text-decoration: underline;}If you want to get really fancy, you can even add syntax highlighting using Rouge.  Reference lists: The quick brown jumped over the lazy. Another way to insert links in markdown is using reference lists. You might want to use this style of linking to cite reference material in a Wikipedia-style. All of the links are listed at the end of the document, so you can maintain full separation between content and its source or reference. Full HTML: Perhaps the best part of Markdown is that you’re never limited to just Markdown. You can write HTML directly in the Markdown editor and it will just work as HTML usually does. No limits! Here’s a standard YouTube embed code as an example: "
    }, {
    "id": 17,
    "url": "/options-for-creating-new-site-with-jekyll/",
    "title": "Options for creating a new site with Jekyll",
    "body": "2019/01/23 - jekyll new &lt;PATH&gt; installs a new Jekyll site at the path specified (relative to current directory). In this case, Jekyll will be installed in a directory called myblog. Here are some additional details:  To install the Jekyll site into the directory you’re currently in, run jekyll new . If the existing directory isn’t empty, you can pass the –force option with jekyll new . –force.  jekyll new automatically initiates bundle install to install the dependencies required. (If you don’t want Bundler to install the gems, use jekyll new myblog --skip-bundle. ) By default, the Jekyll site installed by jekyll new uses a gem-based theme called Minima. With gem-based themes, some of the directories and files are stored in the theme-gem, hidden from your immediate view.  We recommend setting up Jekyll with a gem-based theme but if you want to start with a blank slate, use jekyll new myblog --blank To learn about other parameters you can include with jekyll new, type jekyll new --help. "
    }, {
    "id": 18,
    "url": "/never-stopped-worrying-never-loved-bomb/",
    "title": "Never stopped worrying or loving the bomb",
    "body": "2019/01/22 - I’ve been through fire and water, I tell you! From my earliest pebblehood the wildest things you could imagine have been happening to this world of ours, and I have been right in the midst of them. So begins Hallam Hawksworth’s The Strange Adventures of a Pebble. Written in the 1920s, the book was part of a series which also included The Adventures of a Grain of Dust and A Year in the Wonderland of Trees, all of which were supposed to introduce children to the world of Natural Sciences. In each of them, Hawksworth personifies the natural object he is exploring, and using a mixture of folk tales, scientific facts and colloquial, friendly explanations guides the reader through the history of the natural world. It’s a real thrill of a ride, dramatizing the life cycle of supposedly dull things. The Adventures of a Grain of Dust begins even more loudly than Pebble: I don’t want you to think that I’m boasting, but I do believe I’m one of the greatest travellers that ever was; and if anybody, living or dead, has ever gone through with more than I have I’d like to hear about it.  Hallam Hawksworth was the pen-name of teacher Francis Blake Atkinson. He was married to the author Eleanor Stackhouse Atkinson, author of the children’s classic Greyfriars Bobby, which was based on the (supposedly) true story of a Scottish dog who spent fourteen years guarding his masters grave. The couple were both committed to education and published a weekly magazine for Chicago high school students called The Little Chronicle, as well as working for Encyclopaedia companies later in life. I’ve been through fire and water, I tell you! From my earliest pebblehood the wildest things you could imagine have been happening to this world of ours, and I have been right in the midst of them. So begins Hallam Hawksworth’s The Strange Adventures of a Pebble. Written in the 1920s, the book was part of a series which also included The Adventures of a Grain of Dust and A Year in the Wonderland of Trees, all of which were supposed to introduce children to the world of Natural Sciences. In each of them, Hawksworth personifies the natural object he is exploring, and using a mixture of folk tales, scientific facts and colloquial, friendly explanations guides the reader through the history of the natural world. It’s a real thrill of a ride, dramatizing the life cycle of supposedly dull things. The Adventures of a Grain of Dust begins even more loudly than Pebble: I don’t want you to think that I’m boasting: Hallam Hawksworth was the pen-name of teacher Francis Blake Atkinson. He was married to the author Eleanor Stackhouse Atkinson, author of the children’s classic Greyfriars Bobby, which was based on the (supposedly) true story of a Scottish dog who spent fourteen years guarding his masters grave. The couple were both committed to education and published a weekly magazine for Chicago high school students called The Little Chronicle, as well as working for Encyclopaedia companies later in life. I’ve been through fire and water, I tell you! From my earliest pebblehood the wildest things you could imagine have been happening to this world of ours, and I have been right in the midst of them.  So begins Hallam Hawksworth’s The Strange Adventures of a Pebble. Written in the 1920s, the book was part of a series which also included The Adventures of a Grain of Dust and A Year in the Wonderland of Trees, all of which were supposed to introduce children to the world of Natural Sciences. In each of them, Hawksworth personifies the natural object he is exploring, and using a mixture of folk tales, scientific facts and colloquial, friendly explanations guides the reader through the history of the natural world. It’s a real thrill of a ride, dramatizing the life cycle of supposedly dull things. The Adventures of a Grain of Dust begins even more loudly than Pebble: I don’t want you to think that I’m boasting, but I do believe I’m one of the greatest travellers that ever was; and if anybody, living or dead, has ever gone through with more than I have I’d like to hear about it. Hallam Hawksworth was the pen-name of teacher Francis Blake Atkinson. He was married to the author Eleanor Stackhouse Atkinson, author of the children’s classic Greyfriars Bobby, which was based on the (supposedly) true story of a Scottish dog who spent fourteen years guarding his masters grave. The couple were both committed to education and published a weekly magazine for Chicago high school students called The Little Chronicle, as well as working for Encyclopaedia companies later in life. "
    }, {
    "id": 19,
    "url": "/is-intelligence-enough/",
    "title": "Is Intelligence Enough",
    "body": "2019/01/21 - Education must also train one for quick, resolute and effective thinking. To think incisively and to think for one’s self is very difficult. We are prone to let our mental life become invaded by legions of half truths, prejudices, and propaganda. At this point, I often wonder whether or not education is fulfilling its purpose. A great majority of the so-called educated people do not think logically and scientifically.  Even the press, the classroom, the platform, and the pulpit in many instances do not give us objective and unbiased truths. To save man from the morass of propaganda, in my opinion, is one of the chief aims of education. Education must enable one to sift and weigh evidence, to discern the true from the false, the real from the unreal, and the facts from the fiction. The function of education, therefore, is to teach one to think intensively and to think critically. But education which stops with efficiency may prove the greatest menace to society. The most dangerous criminal may be the man gifted with reason, but with no morals. The late Eugene Talmadge, in my opinion, possessed one of the better minds of Georgia, or even America. Moreover, he wore the Phi Beta Kappa key. By all measuring rods, Mr. Talmadge could think critically and intensively; yet he contends that I am an inferior being. Are those the types of men we call educated? We must remember that intelligence is not enough. Intelligence plus character–that is the goal of true education. The complete education gives one not only power of concentration, but worthy objectives upon which to concentrate. The broad education will, therefore, transmit to one not only the accumulated knowledge of the race but also the accumulated experience of social living. "
    }, {
    "id": 20,
    "url": "/quick-start-guide/",
    "title": "Quick Start Guide",
    "body": "2019/01/20 - If you already have a full Ruby development environment with all headers and RubyGems installed (see Jekyll’s requirements), you can create a new Jekyll site by doing the following: # Install Jekyll and Bundler gems through RubyGemsgem install jekyll bundler# Create a new Jekyll site at . /myblogjekyll new myblog# Change into your new directorycd myblog# Build the site on the preview serverbundle exec jekyll serve# Now browse to http://localhost:4000"
    }, {
    "id": 21,
    "url": "/markup-example/",
    "title": "Markdown Example",
    "body": "2019/01/19 - You’ll find this post in your _posts directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run jekyll serve, which launches a web server and auto-regenerates your site when a file is updated. Something. To add new posts, simply add a file in the _posts directory that follows the convention YYYY-MM-DD-name-of-post. ext and includes the necessary front matter. Take a look at the source for this post to get an idea about how it works. Jekyll also offers powerful support for code snippets: def print_hi(name) puts  Hi, #{name} endprint_hi('Tom')#=&gt; prints 'Hi, Tom' to STDOUT. Check out the Jekyll docs for more info on how to get the most out of Jekyll. File all bugs/feature requests at Jekyll’s GitHub repo. If you have questions, you can ask them on Jekyll Talk. "
    }, {
    "id": 22,
    "url": "/customer-service/",
    "title": "What is Jekyll",
    "body": "2019/01/18 - No more databases, comment moderation, or pesky updates to install-just your content. Markdown, Liquid, HTML &amp; CSS go in. Static sites come out ready for deployment. Permalinks, categories, pages, posts, and custom layouts are all first-class citizens here. Sick of dealing with hosting companies? GitHub Pages are powered by Jekyll, so you can easily deploy your site using GitHub for free-custom domain name and all. What is Jekyll?: Jekyll is a simple, blog-aware, static site generator. You create your content as text files (Markdown), and organize them into folders. Then, you build the shell of your site using Liquid-enhanced HTML templates. Jekyll automatically stitches the content and templates together, generating a website made entirely of static assets, suitable for uploading to any server. Jekyll happens to be the engine behind GitHub Pages, so you can host your project’s Jekyll page/blog/website on GitHub’s servers for free. "
    }, {
    "id": 23,
    "url": "/charm-old-cities/",
    "title": "Could we reinvent the charm of old cities",
    "body": "2019/01/18 - Bucharest’s history alternated periods of development and decline from the early settlements in antiquity until its consolidation as the national capital of Romania late in the 19th century. First mentioned as the “Citadel of București” in 1459, it became the residence of the famous Wallachian prince Vlad III the Impaler. Early 18th century woodcut of Bucharest: The Ottomans appointed Greek administrators (Phanariotes) to run the town from the 18th century. A short-lived revolt initiated by Tudor Vladimirescu in 1821 led to the end of the rule of Constantinople Greeks in Bucharest. [19] The Old Princely Court (Curtea Veche) was erected by Mircea Ciobanul in the mid-16th century. Under subsequent rulers, Bucharest was established as the summer residence of the royal court. During the years to come, it competed with Târgoviște on the status of capital city after an increase in the importance of southern Muntenia brought about by the demands of the suzerain power – the Ottoman Empire. Bucharest finally became the permanent location of the Wallachian court after 1698 (starting with the reign of Constantin Brâncoveanu). Partly destroyed by natural disasters and rebuilt several times during the following 200 years, and hit by Caragea’s plague in 1813–14, the city was wrested from Ottoman control and occupied at several intervals by the Habsburg Monarchy (1716, 1737, 1789) and Imperial Russia (three times between 1768 and 1806). It was placed under Russian administration between 1828 and the Crimean War, with an interlude during the Bucharest-centred 1848 Wallachian revolution. Later, an Austrian garrison took possession after the Russian departure (remaining in the city until March 1857). On 23 March 1847, a fire consumed about 2,000 buildings, destroying a third of the city. "
    }];

var idx = lunr(function () {
    this.ref('id')
    this.field('title')
    this.field('body')

    documents.forEach(function (doc) {
        this.add(doc)
    }, this)
});


    
function lunr_search(term) {
    $('#lunrsearchresults').show( 1000 );
    $( "body" ).addClass( "modal-open" );
    
    document.getElementById('lunrsearchresults').innerHTML = '<div id="resultsmodal" class="modal fade show d-block"  tabindex="-1" role="dialog" aria-labelledby="resultsmodal"> <div class="modal-dialog shadow-lg" role="document"> <div class="modal-content"> <div class="modal-header" id="modtit"> <button type="button" class="close" id="btnx" data-dismiss="modal" aria-label="Close"> &times; </button> </div> <div class="modal-body"> <ul class="mb-0"> </ul>    </div> <div class="modal-footer"><button id="btnx" type="button" class="btn btn-secondary btn-sm" data-dismiss="modal">Close</button></div></div> </div></div>';
    if(term) {
        document.getElementById('modtit').innerHTML = "<h5 class='modal-title'>Search results for '" + term + "'</h5>" + document.getElementById('modtit').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><small><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></small></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>Sorry, no results found. Close & try a different search!</li>";
        }
    }
    return false;
}
</script>
<style>
    .lunrsearchresult .title {color: #d9230f;}
    .lunrsearchresult .url {color: silver;}
    .lunrsearchresult a {display: block; color: #777;}
    .lunrsearchresult a:hover, .lunrsearchresult a:focus {text-decoration: none;}
    .lunrsearchresult a:hover .title {text-decoration: underline;}
</style>




</ul>
<form class="bd-search hidden-sm-down" onsubmit="return lunr_search(document.getElementById('lunrsearch').value);">
<input type="text" class="form-control text-small" id="lunrsearch" name="q" value="" placeholder="Type keyword and enter..."> 
</form>
            
        </div>
    </div>
    </nav>

    <!-- Search Results -->
    <div id="lunrsearchresults">
        <ul class="mb-0"></ul>
    </div>

    <!-- Content -->
    <main role="main" class="site-content">
        
<div class="container">
<div class="jumbotron jumbotron-fluid mb-3 pl-0 pt-0 pb-0 bg-white position-relative">
		<div class="h-100 tofront">
			<div class="row  justify-content-between ">
				<div class=" col-md-6  pr-0 pr-md-4 pt-4 pb-4 align-self-center">
					<p class="text-uppercase font-weight-bold">
                        <span class="catlist">
						
                          <a class="sscroll text-danger" href="/categories.html#jekyll">jekyll</a><span class="sep">, </span>
                        
                          <a class="sscroll text-danger" href="/categories.html#tutorial">tutorial</a><span class="sep">, </span>
                        
                        </span>
					</p>
					<h1 class="display-4 mb-4 article-headline">Options for creating a new site with Jekyll</h1>
					<div class="d-flex align-items-center">
                        
                        <img class="rounded-circle" src="/assets/images/avatar2.jpg" alt="Jane" width="70">
                        
						<small class="ml-3"> Jane <span><a target="_blank" href="https://twitter.com/wowthemesnet" class="btn btn-outline-success btn-sm btn-round ml-1">Follow</a></span>
                            <span class="text-muted d-block mt-1">Jan 23, 2019 · <span class="reading-time">
  
  
    1 min read
  
</span>
    </span>
						</small>
					</div>
				</div>
                
				<div class="col-md-6 pr-0 align-self-center">
					<img class="rounded" src="/assets/images/13.jpg" alt="Options for creating a new site with Jekyll">
				</div>
                
			</div>
		</div>
	</div>
</div>





<div class="container-lg pt-4 pb-4">
	<div class="row justify-content-center">
        
        
        <!-- Share -->
		<div class="col-lg-2 pr-4 mb-4 col-md-12">
			<div class="sticky-top sticky-top-offset text-center">
				<div class="text-muted">
					Share this
				</div>
				<div class="share d-inline-block">
					<!-- AddToAny BEGIN -->
					<div class="a2a_kit a2a_kit_size_32 a2a_default_style">
						<a class="a2a_dd" href="https://www.addtoany.com/share"></a>
						<a class="a2a_button_facebook"></a>
						<a class="a2a_button_twitter"></a>
					</div>
					<script async src="https://static.addtoany.com/menu/page.js"></script>
					<!-- AddToAny END -->
				</div>
			</div>
		</div>
        
        
		<div class="col-md-12 col-lg-8">
            
            <!-- Article -->
			<article class="article-post">                
			<p><code class="language-plaintext highlighter-rouge">jekyll new &lt;PATH&gt;</code> installs a new Jekyll site at the path specified (relative to current directory). In this case, Jekyll will be installed in a directory called <code class="language-plaintext highlighter-rouge">myblog</code>. Here are some additional details:</p>

<ul>
  <li>To install the Jekyll site into the directory you’re currently in, run <code class="language-plaintext highlighter-rouge">jekyll new</code> . If the existing directory isn’t empty, you can pass the –force option with jekyll new . –force.</li>
  <li>
<code class="language-plaintext highlighter-rouge">jekyll new</code> automatically initiates <code class="language-plaintext highlighter-rouge">bundle install</code> to install the dependencies required. (If you don’t want Bundler to install the gems, use <code class="language-plaintext highlighter-rouge">jekyll new myblog --skip-bundle</code>.)</li>
  <li>By default, the Jekyll site installed by <code class="language-plaintext highlighter-rouge">jekyll new</code> uses a gem-based theme called Minima. With gem-based themes, some of the directories and files are stored in the theme-gem, hidden from your immediate view.</li>
  <li>We recommend setting up Jekyll with a gem-based theme but if you want to start with a blank slate, use <code class="language-plaintext highlighter-rouge">jekyll new myblog --blank</code>
</li>
  <li>To learn about other parameters you can include with <code class="language-plaintext highlighter-rouge">jekyll new</code>, type <code class="language-plaintext highlighter-rouge">jekyll new --help</code>.</li>
</ul>
                
			</article>
			
			<!-- Tags -->
			<div class="mb-4">
				<span class="taglist">
				
				</span>
			</div>
 
            <!-- Mailchimp Subscribe Form -->
            
			<div class="border p-5 bg-lightblue">
				<div class="row justify-content-between">
					<div class="col-md-6 mb-2 mb-md-0">
						<h5 class="font-weight-bold">Join Newsletter</h5>
						 Get the latest news right in your inbox. We never spam!
					</div>
					<div class="col-md-6">
						<div class="row">
                            <form action="https://wowthemes.us11.list-manage.com/subscribe/post?u=8aeb20a530e124561927d3bd8&id=8c3d2d214b" method="post" name="mc-embedded-subscribe-form" class="wj-contact-form validate w-100" target="_blank" novalidate>
                            <div class="mc-field-group">
							
								<input type="email" placeholder="Enter e-mail address" name="EMAIL" class="required email form-control w-100" id="mce-EMAIL" autocomplete="on" required>
							
							
								<button type="submit" value="Subscribe" name="subscribe" class="heart btn btn-success btn-block w-100 mt-2">Subscribe</button>
							
                            </div>
                            </form>
						</div>
					</div>
				</div>
			</div>
            
            
            
             <!-- Author Box -->
                				
				<div class="row mt-5">
					<div class="col-md-2 align-self-center">
                         
                        <img class="rounded-circle" src="/assets/images/avatar2.jpg" alt="Jane" width="90">
                         
					</div>
					<div class="col-md-10">		
                        <h5 class="font-weight-bold">Written by Jane <span><a target="_blank" href="https://twitter.com/wowthemesnet" class="btn btn-outline-success btn-sm btn-round ml-2">Follow</a></span>
</h5>
						Blogger, fashionista, love to explore new ideas and write on my morning coffee!					
					</div>
				</div>				
                
            
            <!-- Comments -->
            
                <!--  Don't edit anything here. Set your disqus id in _config.yml -->

<div id="comments" class="mt-5">
    <div id="disqus_thread">
    </div>
    <script type="text/javascript">
        var disqus_shortname = 'demowebsite'; 
        var disqus_developer = 0;
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = window.location.protocol + '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>
    Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a>
    </noscript>
</div>
            
            
		</div>
        
        
	</div>
</div>


<!-- Aletbar Prev/Next -->
<div class="alertbar">
    <div class="container">
        <div class="row prevnextlinks small font-weight-bold">
          
            <div class="col-md-6 rightborder pl-0">
                <a class="text-dark" href="/never-stopped-worrying-never-loved-bomb/"> <img height="30px" class="mr-1" src="/assets/images/14.jpg">  Never stopped worrying or loving the bomb</a>
            </div>
          
          
            <div class="col-md-6 text-right pr-0">
                <a class="text-dark" href="/powerful-things-markdown-editor/"> Powerful things you can do with the Markdown editor  <img height="30px" class="ml-1" src="/assets/images/4.jpg"> </a>
            </div>
          
        </div>
    </div>
</div>

    </main>


    <!-- Scripts: popper, bootstrap, theme, lunr -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js" integrity="sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut" crossorigin="anonymous"></script>

    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js" integrity="sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k" crossorigin="anonymous"></script>

    <script src="/assets/js/theme.js"></script>
    

    <!-- Footer -->
    <footer class="bg-white border-top p-3 text-muted small">
        <div class="container">
        <div class="row align-items-center justify-content-between">
            <div>
                <span class="navbar-brand mr-2 mb-0"><strong>Mundana</strong></span>
                <span>Copyright © <script>document.write(new Date().getFullYear())</script>.</span>

                <!--  Github Repo Star Btn-->
                <a class="text-dark ml-1" target="_blank" href="https://github.com/wowthemesnet/mundana-theme-jekyll"><i class="fab fa-github"></i> Fork on Github</a>

            </div>
            <div>
                Made with <a target="_blank" class="text-dark font-weight-bold" href="https://www.wowthemes.net/mundana-jekyll-theme/"> Mundana Jekyll Theme </a> by <a class="text-dark" target="_blank" href="https://www.wowthemes.net">WowThemes</a>.
            </div>
        </div>
        </div>
    </footer>

    <!-- All this area goes before </body> closing tag --> 


</body>

</html>
